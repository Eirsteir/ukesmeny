{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-17T11:02:18.724801300Z",
     "start_time": "2023-10-17T11:00:33.077389700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# Install necessary dependencies (takes a long time)\n",
    "!pip install torch torch_scatter torch_sparse torch_geometric graphdatascience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from graphdatascience import GraphDataScience\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, RGCNConv\n",
    "from torch_geometric.transforms import RandomNodeSplit\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T11:50:02.611869100Z",
     "start_time": "2023-10-19T11:50:02.580619400Z"
    }
   },
   "id": "7433ca089de8e0b8"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Set seeds for consistent results\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T11:50:04.072151900Z",
     "start_time": "2023-10-19T11:50:04.009651Z"
    }
   },
   "id": "558506b8a770ba8c"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Get Neo4j DB URI, credentials and name from environment if applicable\n",
    "NEO4J_URI = os.environ.get(\"NEO4J_URI\", \"bolt://localhost:7687\")\n",
    "NEO4J_DB = os.environ.get(\"NEO4J_DB\", \"neo4j\")\n",
    "NEO4J_AUTH = (\n",
    "    os.environ.get(\"NEO4J_USER\", \"neo4j\"),\n",
    "    os.environ.get(\"NEO4J_PASSWORD\", \"pleaseletmein\"),\n",
    ")\n",
    "\n",
    "gds = GraphDataScience(NEO4J_URI, auth=NEO4J_AUTH, database=NEO4J_DB)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T11:50:05.938302Z",
     "start_time": "2023-10-19T11:50:05.755077700Z"
    }
   },
   "id": "ddd8d22b7a587458"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def fetch_data(query):\n",
    "    return gds.run_cypher(query)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T11:50:08.936546400Z",
     "start_time": "2023-10-19T11:50:08.920924100Z"
    }
   },
   "id": "d6939e21a13c7fa2"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def load_node(cypher, index_col, encoders=None, target_encoders=None, **kwargs):\n",
    "    # Execute the cypher query and retrieve data from Neo4j\n",
    "    df = fetch_data(cypher)\n",
    "    df.set_index(index_col, inplace=True)\n",
    "    # Define node mapping\n",
    "    mapping = {index: i for i, index in enumerate(df.index.unique())}\n",
    "    # Define node features\n",
    "    x = None\n",
    "    if encoders is not None:\n",
    "        xs = [encoder(df[col]) for col, encoder in encoders.items()]\n",
    "        x = torch.cat(xs, dim=-1)\n",
    "        \n",
    "    y = None\n",
    "    if target_encoders is not None: \n",
    "        ys = [encoder(df[col]) for col, encoder in target_encoders.items()]\n",
    "        y = torch.cat(ys, dim=-1)\n",
    "\n",
    "    return x, mapping, y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T11:50:27.041355400Z",
     "start_time": "2023-10-19T11:50:26.588241100Z"
    }
   },
   "id": "82393231c3d732ab"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def load_edge(cypher, src_index_col, src_mapping, dst_index_col, dst_mapping,\n",
    "                  encoders=None, **kwargs):\n",
    "    # Execute the cypher query and retrieve data from Neo4j\n",
    "    df = fetch_data(cypher)\n",
    "    # Define edge index\n",
    "    src = [src_mapping[index] for index in df[src_index_col]]\n",
    "    dst = [dst_mapping[index] for index in df[dst_index_col]]\n",
    "    edge_index = torch.tensor([src, dst])\n",
    "    # Define edge features\n",
    "    edge_attr = None\n",
    "    if encoders is not None:\n",
    "        edge_attrs = [encoder(df[col]) for col, encoder in encoders.items()]\n",
    "        edge_attr = torch.cat(edge_attrs, dim=-1)\n",
    "\n",
    "    return edge_index, edge_attr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T11:50:27.041355400Z",
     "start_time": "2023-10-19T11:50:26.619486500Z"
    }
   },
   "id": "c4859dd21eecc362"
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "def tags_encoder(tags):\n",
    "    tags_mlb = mlb.fit_transform(tags)\n",
    "    return torch.Tensor(list(tags_mlb))\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class SequenceEncoder:\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2', device=None):\n",
    "        self.device = device\n",
    "        self.model = SentenceTransformer(model_name, device=device)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def __call__(self, df):\n",
    "        x = self.model.encode(df.values, show_progress_bar=True,\n",
    "                              convert_to_tensor=True, device=self.device)\n",
    "        return x.cpu()\n",
    "    \n",
    "class WeekdayEncoder:\n",
    "    def __init__(self, sep='|'):\n",
    "        self.sep = sep\n",
    "\n",
    "    def __call__(self, df):\n",
    "        genres = set(col for col in df.values)\n",
    "        mapping = {genre: i for i, genre in enumerate(genres)}\n",
    "\n",
    "        x = torch.zeros(len(df), len(mapping))\n",
    "        for i, col in enumerate(df.values):\n",
    "            for genre in col.split(self.sep):\n",
    "                x[i, mapping[genre]] = 1\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:39:04.260268900Z",
     "start_time": "2023-10-19T12:39:04.165781900Z"
    }
   },
   "id": "5f2d78ebb62a77eb"
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eirik\\AppData\\Local\\Temp\\ipykernel_5568\\713585520.py:14: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  \"embedding\": lambda x: torch.Tensor(x)\n"
     ]
    }
   ],
   "source": [
    "recipe_query = \"\"\"\n",
    "MATCH (a:Recipe)\n",
    "OPTIONAL MATCH (a)-[:HAS_TAG]->(tag:Tag)\n",
    "RETURN a.recipieId as recipeId,\n",
    "       a.openaiEmbeddings as embedding,\n",
    "       collect(tag.title) AS tags\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "recipe_x, recipe_mapping, recipe_y = load_node(\n",
    "    recipe_query, \n",
    "    index_col='recipeId', \n",
    "    encoders={\n",
    "        \"embedding\": lambda x: torch.Tensor(x)\n",
    "    },\n",
    "    target_encoders={\n",
    "        \"tags\": tags_encoder\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:39:10.961650600Z",
     "start_time": "2023-10-19T12:39:05.933606700Z"
    }
   },
   "id": "e9e1f14a0cc1da20"
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([723, 1536]), 723, torch.Size([723, 262]))"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_x.shape, len(recipe_mapping), recipe_y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:18:31.228343400Z",
     "start_time": "2023-10-19T12:18:31.134590400Z"
    }
   },
   "id": "7a8f888fdda9137f"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/57 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "56ff912acc7b4dcbbe918c6b10e4a5b6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ingredient_query = \"\"\"\n",
    "MATCH (i:Ingredient)\n",
    "RETURN ID(i) as ingredientId, i.title as title\n",
    "\"\"\"\n",
    "ingredient_x, ingredient_mapping, y = load_node(\n",
    "    ingredient_query, \n",
    "    index_col='ingredientId', \n",
    "    encoders={\n",
    "        'title': SequenceEncoder()\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T11:50:47.274906Z",
     "start_time": "2023-10-19T11:50:38.324045Z"
    }
   },
   "id": "d6fdcf042951fc0"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([1793, 384]), 1793)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredient_x.shape, len(ingredient_mapping)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T11:50:47.308285Z",
     "start_time": "2023-10-19T11:50:47.279909200Z"
    }
   },
   "id": "6dd3de1c20740129"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "menu_query = \"\"\"\n",
    "MATCH (m:Menu)\n",
    "RETURN ID(m) as menuId, m.year as year, m.week as week\n",
    "\"\"\"\n",
    "menu_x, menu_mapping, y = load_node(\n",
    "    menu_query, \n",
    "    index_col='menuId',\n",
    "    encoders={\n",
    "        \"year\": lambda x: torch.Tensor(x.tolist()).view(-1, 1),\n",
    "        \"week\": lambda x: torch.Tensor(x.tolist()).view(-1, 1),\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T11:50:47.484635900Z",
     "start_time": "2023-10-19T11:50:47.298915700Z"
    }
   },
   "id": "101ad49116b3994f"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([142, 2]), 142)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "menu_x.shape, len(menu_mapping)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T11:50:47.500808500Z",
     "start_time": "2023-10-19T11:50:47.484635900Z"
    }
   },
   "id": "40da01b9dfcfad8d"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "recipe_menu_query = \"\"\"\n",
    "MATCH (n:Recipe)-[:HAS_TAG]->(:Tag), (n)-[r:IS_PART_OF_MENU]->(m:Menu)\n",
    "RETURN DISTINCT n.recipieId AS recipeId, ID(m) AS menuId, r.weekDay AS weekDay\n",
    "\"\"\"\n",
    "\n",
    "recipe_menu_edge_index, recipe_menu_edge_label = load_edge(\n",
    "    recipe_menu_query,\n",
    "    src_index_col='recipeId',\n",
    "    src_mapping=recipe_mapping,\n",
    "    dst_index_col='menuId',\n",
    "    dst_mapping=menu_mapping,\n",
    "    encoders={'weekDay': WeekdayEncoder()},\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:21:12.333348900Z",
     "start_time": "2023-10-19T12:21:12.025057100Z"
    }
   },
   "id": "5b201cdc7df4b23f"
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([2, 698]), torch.Size([698, 7]))"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_menu_edge_index.shape, recipe_menu_edge_label.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:21:14.457994Z",
     "start_time": "2023-10-19T12:21:14.423512600Z"
    }
   },
   "id": "b3a76f187ca70691"
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "recipe_ingredient_query = \"\"\"\n",
    "MATCH (n:Recipe)-[:HAS_TAG]->(:Tag), (n)-[r:HAS_INGREDIENT]->(i:Ingredient) \n",
    "RETURN DISTINCT n.recipieId AS recipeId, ID(i) AS ingredientId\n",
    "\"\"\"\n",
    "\n",
    "recipe_ingredient_edge_index, recipe_ingredient_edge_label = load_edge(\n",
    "    recipe_ingredient_query,\n",
    "    src_index_col='recipeId',\n",
    "    src_mapping=recipe_mapping,\n",
    "    dst_index_col='ingredientId',\n",
    "    dst_mapping=ingredient_mapping,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:21:54.731633700Z",
     "start_time": "2023-10-19T12:21:53.844050100Z"
    }
   },
   "id": "e63569124aef7cec"
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([2, 5921]), None)"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_ingredient_edge_index.shape, recipe_ingredient_edge_label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:21:55.683743200Z",
     "start_time": "2023-10-19T12:21:55.652499600Z"
    }
   },
   "id": "7bf086b1809709f5"
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "HeteroData(\n  num_relations=2,\n  num_classes=262,\n  num_nodes=2658,\n  recipe={\n    x=[723, 1536],\n    y=[723, 262],\n  },\n  menu={ x=[142, 2] },\n  ingredient={ x=[1793, 384] },\n  (recipe, has_ingredient, ingredient)={ edge_index=[2, 5921] },\n  (recipe, is_part_of_menu, menu)={\n    edge_index=[2, 698],\n    edge_attr=[698, 7],\n  }\n)"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "data = HeteroData()\n",
    "\n",
    "data['recipe'].x = recipe_x\n",
    "data['recipe'].y = recipe_y\n",
    "data[\"menu\"].x = menu_x\n",
    "data[\"ingredient\"].x = ingredient_x\n",
    "data[\"recipe\", \"has_ingredient\", \"ingredient\"].edge_index = recipe_ingredient_edge_index\n",
    "data[\"recipe\", \"is_part_of_menu\", \"menu\"].edge_index = recipe_menu_edge_index\n",
    "data[\"recipe\", \"is_part_of_menu\", \"menu\"].edge_attr = recipe_menu_edge_label\n",
    "data.num_relations = 2\n",
    "data.num_classes = recipe_y.shape[-1]\n",
    "data.num_nodes = len(recipe_mapping) + len(ingredient_mapping) + len(menu_mapping)\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:21:58.353683300Z",
     "start_time": "2023-10-19T12:21:58.294284900Z"
    }
   },
   "id": "7ed42e63f442ae0f"
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "HeteroData(\n  num_relations=2,\n  num_classes=262,\n  num_nodes=2658,\n  recipe={\n    x=[723, 1536],\n    y=[723, 262],\n  },\n  menu={ x=[142, 2] },\n  ingredient={ x=[1793, 384] },\n  (recipe, has_ingredient, ingredient)={ edge_index=[2, 5921] },\n  (recipe, is_part_of_menu, menu)={\n    edge_index=[2, 698],\n    edge_attr=[698, 7],\n  },\n  (ingredient, rev_has_ingredient, recipe)={ edge_index=[2, 5921] },\n  (menu, rev_is_part_of_menu, recipe)={\n    edge_index=[2, 698],\n    edge_attr=[698, 7],\n  }\n)"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.transforms import ToUndirected\n",
    "\n",
    "data = ToUndirected()(data)\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:22:00.621449600Z",
     "start_time": "2023-10-19T12:22:00.590199200Z"
    }
   },
   "id": "b92685477f3427aa"
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "\n",
    "# 2. Perform a link-level split into training, validation, and test edges.\n",
    "transform = RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    neg_sampling_ratio=0.0,\n",
    "    edge_types=[(\"recipe\", \"is_part_of_menu\", \"menu\"), (\"recipe\", \"has_ingredient\", \"ingredient\")],\n",
    "    # rev_edge_types=[('movie', 'rev_rates', 'user')],\n",
    ")\n",
    "train_data, val_data, test_data = transform(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:22:03.049600Z",
     "start_time": "2023-10-19T12:22:02.929615400Z"
    }
   },
   "id": "40fbc3b48bf3660d"
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "[('recipe', 'has_ingredient', 'ingredient'),\n ('recipe', 'is_part_of_menu', 'menu'),\n ('ingredient', 'rev_has_ingredient', 'recipe'),\n ('menu', 'rev_is_part_of_menu', 'recipe')]"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.metadata()[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:22:07.644050700Z",
     "start_time": "2023-10-19T12:22:07.612805Z"
    }
   },
   "id": "27ca4cc406072ed3"
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv, Linear, to_hetero\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv((-1, -1), hidden_channels, add_self_loops=False)\n",
    "        self.lin1 = Linear(-1, hidden_channels)\n",
    "        self.conv2 = GATConv((-1, -1), out_channels, add_self_loops=False)\n",
    "        self.lin2 = Linear(-1, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index) + self.lin1(x)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index) + self.lin2(x)\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:22:13.210672600Z",
     "start_time": "2023-10-19T12:22:13.190166400Z"
    }
   },
   "id": "3aa6fd54bef8a3ef"
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "model = GAT(hidden_channels=64, out_channels=data.num_classes)\n",
    "model = to_hetero(model, data.metadata(), aggr='sum')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data, model = data.to(device), model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:22:14.536812300Z",
     "start_time": "2023-10-19T12:22:14.284762100Z"
    }
   },
   "id": "4882d5703529724"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "with torch.no_grad():  # Initialize lazy modules.\n",
    "    out = model(data.x_dict, data.edge_index_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:03:09.931743300Z",
     "start_time": "2023-10-19T12:03:09.851754900Z"
    }
   },
   "id": "5156a1b9be873093"
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 76.69147491455078\n",
      "Validation Loss: 49.7157096862793\n",
      "Epoch 2, Loss: 49.7157096862793\n",
      "Validation Loss: 27.945297241210938\n",
      "Epoch 3, Loss: 27.945297241210938\n",
      "Validation Loss: 14.334324836730957\n",
      "Epoch 4, Loss: 14.334324836730957\n",
      "Validation Loss: 8.50998306274414\n",
      "Epoch 5, Loss: 8.50998306274414\n",
      "Validation Loss: 5.360548973083496\n",
      "Epoch 6, Loss: 5.360548973083496\n",
      "Validation Loss: 4.900411128997803\n",
      "Epoch 7, Loss: 4.900411128997803\n",
      "Validation Loss: 4.559986591339111\n",
      "Epoch 8, Loss: 4.559986591339111\n",
      "Validation Loss: 4.417131423950195\n",
      "Epoch 9, Loss: 4.417131423950195\n",
      "Validation Loss: 4.963930130004883\n",
      "Epoch 10, Loss: 4.963930130004883\n",
      "Validation Loss: 4.875558853149414\n",
      "Epoch 11, Loss: 4.875558853149414\n",
      "Validation Loss: 4.920295238494873\n",
      "Epoch 12, Loss: 4.920295238494873\n",
      "Validation Loss: 5.022231101989746\n",
      "Epoch 13, Loss: 5.022231101989746\n",
      "Validation Loss: 5.022214889526367\n",
      "Epoch 14, Loss: 5.022214889526367\n",
      "Validation Loss: 4.886704921722412\n",
      "Epoch 15, Loss: 4.886704921722412\n",
      "Validation Loss: 4.799882888793945\n",
      "Epoch 16, Loss: 4.799882888793945\n",
      "Validation Loss: 4.651937484741211\n",
      "Epoch 17, Loss: 4.651937484741211\n",
      "Validation Loss: 4.56636905670166\n",
      "Epoch 18, Loss: 4.56636905670166\n",
      "Validation Loss: 4.347907543182373\n",
      "Epoch 19, Loss: 4.347907543182373\n",
      "Validation Loss: 4.065169334411621\n",
      "Epoch 20, Loss: 4.065169334411621\n",
      "Validation Loss: 4.216762065887451\n",
      "Epoch 21, Loss: 4.216762065887451\n",
      "Validation Loss: 4.388893127441406\n",
      "Epoch 22, Loss: 4.388893127441406\n",
      "Validation Loss: 4.203922748565674\n",
      "Epoch 23, Loss: 4.203922748565674\n",
      "Validation Loss: 4.047519683837891\n",
      "Epoch 24, Loss: 4.047519683837891\n",
      "Validation Loss: 3.93095064163208\n",
      "Epoch 25, Loss: 3.93095064163208\n",
      "Validation Loss: 3.9029006958007812\n",
      "Epoch 26, Loss: 3.9029006958007812\n",
      "Validation Loss: 3.73899507522583\n",
      "Epoch 27, Loss: 3.73899507522583\n",
      "Validation Loss: 3.6368825435638428\n",
      "Epoch 28, Loss: 3.6368825435638428\n",
      "Validation Loss: 3.5822629928588867\n",
      "Epoch 29, Loss: 3.5822629928588867\n",
      "Validation Loss: 3.549403429031372\n",
      "Epoch 30, Loss: 3.549403429031372\n",
      "Validation Loss: 3.385124683380127\n",
      "Epoch 31, Loss: 3.385124683380127\n",
      "Validation Loss: 3.192909002304077\n",
      "Epoch 32, Loss: 3.192909002304077\n",
      "Validation Loss: 3.053766965866089\n",
      "Epoch 33, Loss: 3.053766965866089\n",
      "Validation Loss: 2.9777989387512207\n",
      "Epoch 34, Loss: 2.9777989387512207\n",
      "Validation Loss: 2.8969812393188477\n",
      "Epoch 35, Loss: 2.8969812393188477\n",
      "Validation Loss: 2.8060855865478516\n",
      "Epoch 36, Loss: 2.8060855865478516\n",
      "Validation Loss: 2.5912420749664307\n",
      "Epoch 37, Loss: 2.5912420749664307\n",
      "Validation Loss: 2.5551505088806152\n",
      "Epoch 38, Loss: 2.5551505088806152\n",
      "Validation Loss: 2.561272621154785\n",
      "Epoch 39, Loss: 2.561272621154785\n",
      "Validation Loss: 2.475985288619995\n",
      "Epoch 40, Loss: 2.475985288619995\n",
      "Validation Loss: 2.386387586593628\n",
      "Epoch 41, Loss: 2.386387586593628\n",
      "Validation Loss: 2.3771631717681885\n",
      "Epoch 42, Loss: 2.3771631717681885\n",
      "Validation Loss: 2.274245500564575\n",
      "Epoch 43, Loss: 2.274245500564575\n",
      "Validation Loss: 2.245986223220825\n",
      "Epoch 44, Loss: 2.245986223220825\n",
      "Validation Loss: 2.159492254257202\n",
      "Epoch 45, Loss: 2.159492254257202\n",
      "Validation Loss: 2.045696258544922\n",
      "Epoch 46, Loss: 2.045696258544922\n",
      "Validation Loss: 2.029721736907959\n",
      "Epoch 47, Loss: 2.029721736907959\n",
      "Validation Loss: 1.9899835586547852\n",
      "Epoch 48, Loss: 1.9899835586547852\n",
      "Validation Loss: 1.8854082822799683\n",
      "Epoch 49, Loss: 1.8854082822799683\n",
      "Validation Loss: 1.9914056062698364\n",
      "Epoch 50, Loss: 1.9914056062698364\n",
      "Validation Loss: 1.8368802070617676\n",
      "Epoch 51, Loss: 1.8368802070617676\n",
      "Validation Loss: 1.8006701469421387\n",
      "Epoch 52, Loss: 1.8006701469421387\n",
      "Validation Loss: 1.890801191329956\n",
      "Epoch 53, Loss: 1.890801191329956\n",
      "Validation Loss: 1.7288622856140137\n",
      "Epoch 54, Loss: 1.7288622856140137\n",
      "Validation Loss: 1.6744426488876343\n",
      "Epoch 55, Loss: 1.6744426488876343\n",
      "Validation Loss: 1.752456784248352\n",
      "Epoch 56, Loss: 1.752456784248352\n",
      "Validation Loss: 1.681062936782837\n",
      "Epoch 57, Loss: 1.681062936782837\n",
      "Validation Loss: 1.6284269094467163\n",
      "Epoch 58, Loss: 1.6284269094467163\n",
      "Validation Loss: 1.6495461463928223\n",
      "Epoch 59, Loss: 1.6495461463928223\n",
      "Validation Loss: 1.5270532369613647\n",
      "Epoch 60, Loss: 1.5270532369613647\n",
      "Validation Loss: 1.5438555479049683\n",
      "Epoch 61, Loss: 1.5438555479049683\n",
      "Validation Loss: 1.4546750783920288\n",
      "Epoch 62, Loss: 1.4546750783920288\n",
      "Validation Loss: 1.4339407682418823\n",
      "Epoch 63, Loss: 1.4339407682418823\n",
      "Validation Loss: 1.3681325912475586\n",
      "Epoch 64, Loss: 1.3681325912475586\n",
      "Validation Loss: 1.258333683013916\n",
      "Epoch 65, Loss: 1.258333683013916\n",
      "Validation Loss: 1.2038055658340454\n",
      "Epoch 66, Loss: 1.2038055658340454\n",
      "Validation Loss: 1.1926164627075195\n",
      "Epoch 67, Loss: 1.1926164627075195\n",
      "Validation Loss: 1.2076985836029053\n",
      "Epoch 68, Loss: 1.2076985836029053\n",
      "Validation Loss: 1.20166015625\n",
      "Epoch 69, Loss: 1.20166015625\n",
      "Validation Loss: 1.1865988969802856\n",
      "Epoch 70, Loss: 1.1865988969802856\n",
      "Validation Loss: 1.1742949485778809\n",
      "Epoch 71, Loss: 1.1742949485778809\n",
      "Validation Loss: 1.1271647214889526\n",
      "Epoch 72, Loss: 1.1271647214889526\n",
      "Validation Loss: 1.1557799577713013\n",
      "Epoch 73, Loss: 1.1557799577713013\n",
      "Validation Loss: 1.13642156124115\n",
      "Epoch 74, Loss: 1.13642156124115\n",
      "Validation Loss: 1.1355141401290894\n",
      "Epoch 75, Loss: 1.1355141401290894\n",
      "Validation Loss: 1.1052446365356445\n",
      "Epoch 76, Loss: 1.1052446365356445\n",
      "Validation Loss: 1.1119228601455688\n",
      "Epoch 77, Loss: 1.1119228601455688\n",
      "Validation Loss: 1.1294317245483398\n",
      "Epoch 78, Loss: 1.1294317245483398\n",
      "Validation Loss: 1.0623337030410767\n",
      "Epoch 79, Loss: 1.0623337030410767\n",
      "Validation Loss: 1.0615884065628052\n",
      "Epoch 80, Loss: 1.0615884065628052\n",
      "Validation Loss: 1.053524374961853\n",
      "Epoch 81, Loss: 1.053524374961853\n",
      "Validation Loss: 1.0412664413452148\n",
      "Epoch 82, Loss: 1.0412664413452148\n",
      "Validation Loss: 1.0302238464355469\n",
      "Epoch 83, Loss: 1.0302238464355469\n",
      "Validation Loss: 0.9830923676490784\n",
      "Epoch 84, Loss: 0.9830923676490784\n",
      "Validation Loss: 1.0115556716918945\n",
      "Epoch 85, Loss: 1.0115556716918945\n",
      "Validation Loss: 1.0400203466415405\n",
      "Epoch 86, Loss: 1.0400203466415405\n",
      "Validation Loss: 1.0608237981796265\n",
      "Epoch 87, Loss: 1.0608237981796265\n",
      "Validation Loss: 0.9646593332290649\n",
      "Epoch 88, Loss: 0.9646593332290649\n",
      "Validation Loss: 0.9708858132362366\n",
      "Epoch 89, Loss: 0.9708858132362366\n",
      "Validation Loss: 0.997736394405365\n",
      "Epoch 90, Loss: 0.997736394405365\n",
      "Validation Loss: 0.9978362321853638\n",
      "Epoch 91, Loss: 0.9978362321853638\n",
      "Validation Loss: 0.9628691673278809\n",
      "Epoch 92, Loss: 0.9628691673278809\n",
      "Validation Loss: 0.9459210634231567\n",
      "Epoch 93, Loss: 0.9459210634231567\n",
      "Validation Loss: 0.9498746991157532\n",
      "Epoch 94, Loss: 0.9498746991157532\n",
      "Validation Loss: 0.9271420836448669\n",
      "Epoch 95, Loss: 0.9271420836448669\n",
      "Validation Loss: 0.9643728733062744\n",
      "Epoch 96, Loss: 0.9643728733062744\n",
      "Validation Loss: 0.9232883453369141\n",
      "Epoch 97, Loss: 0.9232883453369141\n",
      "Validation Loss: 0.889615535736084\n",
      "Epoch 98, Loss: 0.889615535736084\n",
      "Validation Loss: 0.8984423875808716\n",
      "Epoch 99, Loss: 0.8984423875808716\n",
      "Validation Loss: 0.8931114673614502\n",
      "Epoch 100, Loss: 0.8931114673614502\n",
      "Validation Loss: 0.8649629354476929\n",
      "Epoch 101, Loss: 0.8649629354476929\n",
      "Validation Loss: 0.8224657773971558\n",
      "Epoch 102, Loss: 0.8224657773971558\n",
      "Validation Loss: 0.8959391713142395\n",
      "Epoch 103, Loss: 0.8959391713142395\n",
      "Validation Loss: 0.8242453336715698\n",
      "Epoch 104, Loss: 0.8242453336715698\n",
      "Validation Loss: 0.8436005115509033\n",
      "Epoch 105, Loss: 0.8436005115509033\n",
      "Validation Loss: 0.8045762181282043\n",
      "Epoch 106, Loss: 0.8045762181282043\n",
      "Validation Loss: 0.8314641118049622\n",
      "Epoch 107, Loss: 0.8314641118049622\n",
      "Validation Loss: 0.8218137621879578\n",
      "Epoch 108, Loss: 0.8218137621879578\n",
      "Validation Loss: 0.8441872000694275\n",
      "Epoch 109, Loss: 0.8441872000694275\n",
      "Validation Loss: 0.8097632527351379\n",
      "Epoch 110, Loss: 0.8097632527351379\n",
      "Validation Loss: 0.8074129223823547\n",
      "Epoch 111, Loss: 0.8074129223823547\n",
      "Validation Loss: 0.814870297908783\n",
      "Epoch 112, Loss: 0.814870297908783\n",
      "Validation Loss: 0.8550296425819397\n",
      "Epoch 113, Loss: 0.8550296425819397\n",
      "Validation Loss: 0.8023439049720764\n",
      "Epoch 114, Loss: 0.8023439049720764\n",
      "Validation Loss: 0.7877033948898315\n",
      "Epoch 115, Loss: 0.7877033948898315\n",
      "Validation Loss: 0.7884043455123901\n",
      "Epoch 116, Loss: 0.7884043455123901\n",
      "Validation Loss: 0.7710890173912048\n",
      "Epoch 117, Loss: 0.7710890173912048\n",
      "Validation Loss: 0.8126587271690369\n",
      "Epoch 118, Loss: 0.8126587271690369\n",
      "Validation Loss: 0.7629029750823975\n",
      "Epoch 119, Loss: 0.7629029750823975\n",
      "Validation Loss: 0.7786158919334412\n",
      "Epoch 120, Loss: 0.7786158919334412\n",
      "Validation Loss: 0.7528689503669739\n",
      "Epoch 121, Loss: 0.7528689503669739\n",
      "Validation Loss: 0.7614461183547974\n",
      "Epoch 122, Loss: 0.7614461183547974\n",
      "Validation Loss: 0.7785148620605469\n",
      "Epoch 123, Loss: 0.7785148620605469\n",
      "Validation Loss: 0.776341438293457\n",
      "Epoch 124, Loss: 0.776341438293457\n",
      "Validation Loss: 0.7963243126869202\n",
      "Epoch 125, Loss: 0.7963243126869202\n",
      "Validation Loss: 0.8101798295974731\n",
      "Epoch 126, Loss: 0.8101798295974731\n",
      "Validation Loss: 0.8696121573448181\n",
      "Epoch 127, Loss: 0.8696121573448181\n",
      "Validation Loss: 0.8384020924568176\n",
      "Epoch 128, Loss: 0.8384020924568176\n",
      "Validation Loss: 0.798041045665741\n",
      "Epoch 129, Loss: 0.798041045665741\n",
      "Validation Loss: 0.803149402141571\n",
      "Epoch 130, Loss: 0.803149402141571\n",
      "Validation Loss: 0.7928335070610046\n",
      "Epoch 131, Loss: 0.7928335070610046\n",
      "Validation Loss: 0.7563096284866333\n",
      "Epoch 132, Loss: 0.7563096284866333\n",
      "Validation Loss: 0.7567315101623535\n",
      "Epoch 133, Loss: 0.7567315101623535\n",
      "Validation Loss: 0.7546210289001465\n",
      "Epoch 134, Loss: 0.7546210289001465\n",
      "Validation Loss: 0.7673472166061401\n",
      "Epoch 135, Loss: 0.7673472166061401\n",
      "Validation Loss: 0.754033088684082\n",
      "Epoch 136, Loss: 0.754033088684082\n",
      "Validation Loss: 0.7849900722503662\n",
      "Epoch 137, Loss: 0.7849900722503662\n",
      "Validation Loss: 0.7674999237060547\n",
      "Epoch 138, Loss: 0.7674999237060547\n",
      "Validation Loss: 0.7600069046020508\n",
      "Epoch 139, Loss: 0.7600069046020508\n",
      "Validation Loss: 0.7568348050117493\n",
      "Epoch 140, Loss: 0.7568348050117493\n",
      "Validation Loss: 0.7709681391716003\n",
      "Epoch 141, Loss: 0.7709681391716003\n",
      "Validation Loss: 0.7446509599685669\n",
      "Epoch 142, Loss: 0.7446509599685669\n",
      "Validation Loss: 0.8049859404563904\n",
      "Epoch 143, Loss: 0.8049859404563904\n",
      "Validation Loss: 0.7563846707344055\n",
      "Epoch 144, Loss: 0.7563846707344055\n",
      "Validation Loss: 0.8167158365249634\n",
      "Epoch 145, Loss: 0.8167158365249634\n",
      "Validation Loss: 0.7432136535644531\n",
      "Epoch 146, Loss: 0.7432136535644531\n",
      "Validation Loss: 0.8409906625747681\n",
      "Epoch 147, Loss: 0.8409906625747681\n",
      "Validation Loss: 0.7555785179138184\n",
      "Epoch 148, Loss: 0.7555785179138184\n",
      "Validation Loss: 0.7930250763893127\n",
      "Epoch 149, Loss: 0.7930250763893127\n",
      "Validation Loss: 0.7855364084243774\n",
      "Epoch 150, Loss: 0.7855364084243774\n",
      "Validation Loss: 0.822624921798706\n",
      "Epoch 151, Loss: 0.822624921798706\n",
      "Validation Loss: 0.7783423662185669\n",
      "Epoch 152, Loss: 0.7783423662185669\n",
      "Validation Loss: 0.7942368388175964\n",
      "Epoch 153, Loss: 0.7942368388175964\n",
      "Validation Loss: 0.7658848166465759\n",
      "Epoch 154, Loss: 0.7658848166465759\n",
      "Validation Loss: 0.7753036618232727\n",
      "Epoch 155, Loss: 0.7753036618232727\n",
      "Validation Loss: 0.770147442817688\n",
      "Epoch 156, Loss: 0.770147442817688\n",
      "Validation Loss: 0.7437966465950012\n",
      "Epoch 157, Loss: 0.7437966465950012\n",
      "Validation Loss: 0.7526664733886719\n",
      "Epoch 158, Loss: 0.7526664733886719\n",
      "Validation Loss: 0.76604825258255\n",
      "Epoch 159, Loss: 0.76604825258255\n",
      "Validation Loss: 0.7385611534118652\n",
      "Epoch 160, Loss: 0.7385611534118652\n",
      "Validation Loss: 0.7200589179992676\n",
      "Epoch 161, Loss: 0.7200589179992676\n",
      "Validation Loss: 0.7658663392066956\n",
      "Epoch 162, Loss: 0.7658663392066956\n",
      "Validation Loss: 0.7436749935150146\n",
      "Epoch 163, Loss: 0.7436749935150146\n",
      "Validation Loss: 0.739598274230957\n",
      "Epoch 164, Loss: 0.739598274230957\n",
      "Validation Loss: 0.7370267510414124\n",
      "Epoch 165, Loss: 0.7370267510414124\n",
      "Validation Loss: 0.7293738126754761\n",
      "Epoch 166, Loss: 0.7293738126754761\n",
      "Validation Loss: 0.7343264222145081\n",
      "Epoch 167, Loss: 0.7343264222145081\n",
      "Validation Loss: 0.7060293555259705\n",
      "Epoch 168, Loss: 0.7060293555259705\n",
      "Validation Loss: 0.6852537989616394\n",
      "Epoch 169, Loss: 0.6852537989616394\n",
      "Validation Loss: 0.7033652663230896\n",
      "Epoch 170, Loss: 0.7033652663230896\n",
      "Validation Loss: 0.7286407351493835\n",
      "Epoch 171, Loss: 0.7286407351493835\n",
      "Validation Loss: 0.7186055779457092\n",
      "Epoch 172, Loss: 0.7186055779457092\n",
      "Validation Loss: 0.7018121480941772\n",
      "Epoch 173, Loss: 0.7018121480941772\n",
      "Validation Loss: 0.7145470976829529\n",
      "Epoch 174, Loss: 0.7145470976829529\n",
      "Validation Loss: 0.7150524258613586\n",
      "Epoch 175, Loss: 0.7150524258613586\n",
      "Validation Loss: 0.730460524559021\n",
      "Epoch 176, Loss: 0.730460524559021\n",
      "Validation Loss: 0.7437300682067871\n",
      "Epoch 177, Loss: 0.7437300682067871\n",
      "Validation Loss: 0.7313132286071777\n",
      "Epoch 178, Loss: 0.7313132286071777\n",
      "Validation Loss: 0.6987801194190979\n",
      "Epoch 179, Loss: 0.6987801194190979\n",
      "Validation Loss: 0.7276578545570374\n",
      "Epoch 180, Loss: 0.7276578545570374\n",
      "Validation Loss: 0.7124972343444824\n",
      "Epoch 181, Loss: 0.7124972343444824\n",
      "Validation Loss: 0.7470033764839172\n",
      "Epoch 182, Loss: 0.7470033764839172\n",
      "Validation Loss: 0.7122265696525574\n",
      "Epoch 183, Loss: 0.7122265696525574\n",
      "Validation Loss: 0.7139869928359985\n",
      "Epoch 184, Loss: 0.7139869928359985\n",
      "Validation Loss: 0.7166041135787964\n",
      "Epoch 185, Loss: 0.7166041135787964\n",
      "Validation Loss: 0.7526426911354065\n",
      "Epoch 186, Loss: 0.7526426911354065\n",
      "Validation Loss: 0.7184505462646484\n",
      "Epoch 187, Loss: 0.7184505462646484\n",
      "Validation Loss: 0.7060971260070801\n",
      "Epoch 188, Loss: 0.7060971260070801\n",
      "Validation Loss: 0.6936067938804626\n",
      "Epoch 189, Loss: 0.6936067938804626\n",
      "Validation Loss: 0.6982603669166565\n",
      "Epoch 190, Loss: 0.6982603669166565\n",
      "Validation Loss: 0.6727120876312256\n",
      "Epoch 191, Loss: 0.6727120876312256\n",
      "Validation Loss: 0.678082287311554\n",
      "Epoch 192, Loss: 0.678082287311554\n",
      "Validation Loss: 0.6686188578605652\n",
      "Epoch 193, Loss: 0.6686188578605652\n",
      "Validation Loss: 0.662251353263855\n",
      "Epoch 194, Loss: 0.662251353263855\n",
      "Validation Loss: 0.6834074258804321\n",
      "Epoch 195, Loss: 0.6834074258804321\n",
      "Validation Loss: 0.6345090866088867\n",
      "Epoch 196, Loss: 0.6345090866088867\n",
      "Validation Loss: 0.6914224028587341\n",
      "Epoch 197, Loss: 0.6914224028587341\n",
      "Validation Loss: 0.6827494502067566\n",
      "Epoch 198, Loss: 0.6827494502067566\n",
      "Validation Loss: 0.6801703572273254\n",
      "Epoch 199, Loss: 0.6801703572273254\n",
      "Validation Loss: 0.6657835841178894\n",
      "Epoch 200, Loss: 0.6657835841178894\n",
      "Validation Loss: 0.7112401127815247\n",
      "Epoch 201, Loss: 0.7112401127815247\n",
      "Validation Loss: 0.6814693808555603\n",
      "Epoch 202, Loss: 0.6814693808555603\n",
      "Validation Loss: 0.6862786412239075\n",
      "Epoch 203, Loss: 0.6862786412239075\n",
      "Validation Loss: 0.6841595768928528\n",
      "Epoch 204, Loss: 0.6841595768928528\n",
      "Validation Loss: 0.7211989164352417\n",
      "Epoch 205, Loss: 0.7211989164352417\n",
      "Validation Loss: 0.680305004119873\n",
      "Epoch 206, Loss: 0.680305004119873\n",
      "Validation Loss: 0.6824204325675964\n",
      "Epoch 207, Loss: 0.6824204325675964\n",
      "Validation Loss: 0.6833685040473938\n",
      "Epoch 208, Loss: 0.6833685040473938\n",
      "Validation Loss: 0.6704882979393005\n",
      "Epoch 209, Loss: 0.6704882979393005\n",
      "Validation Loss: 0.6494879722595215\n",
      "Epoch 210, Loss: 0.6494879722595215\n",
      "Validation Loss: 0.6554296612739563\n",
      "Epoch 211, Loss: 0.6554296612739563\n",
      "Validation Loss: 0.631557822227478\n",
      "Epoch 212, Loss: 0.631557822227478\n",
      "Validation Loss: 0.6345679759979248\n",
      "Epoch 213, Loss: 0.6345679759979248\n",
      "Validation Loss: 0.6801121830940247\n",
      "Epoch 214, Loss: 0.6801121830940247\n",
      "Validation Loss: 0.6565759778022766\n",
      "Epoch 215, Loss: 0.6565759778022766\n",
      "Validation Loss: 0.6689580678939819\n",
      "Epoch 216, Loss: 0.6689580678939819\n",
      "Validation Loss: 0.6999347805976868\n",
      "Epoch 217, Loss: 0.6999347805976868\n",
      "Validation Loss: 0.6615836024284363\n",
      "Epoch 218, Loss: 0.6615836024284363\n",
      "Validation Loss: 0.6767176985740662\n",
      "Epoch 219, Loss: 0.6767176985740662\n",
      "Validation Loss: 0.6242082118988037\n",
      "Epoch 220, Loss: 0.6242082118988037\n",
      "Validation Loss: 0.6137815117835999\n",
      "Epoch 221, Loss: 0.6137815117835999\n",
      "Validation Loss: 0.6511315107345581\n",
      "Epoch 222, Loss: 0.6511315107345581\n",
      "Validation Loss: 0.6333255171775818\n",
      "Epoch 223, Loss: 0.6333255171775818\n",
      "Validation Loss: 0.6092209815979004\n",
      "Epoch 224, Loss: 0.6092209815979004\n",
      "Validation Loss: 0.6083890199661255\n",
      "Epoch 225, Loss: 0.6083890199661255\n",
      "Validation Loss: 0.64336758852005\n",
      "Epoch 226, Loss: 0.64336758852005\n",
      "Validation Loss: 0.6076787710189819\n",
      "Epoch 227, Loss: 0.6076787710189819\n",
      "Validation Loss: 0.6384660005569458\n",
      "Epoch 228, Loss: 0.6384660005569458\n",
      "Validation Loss: 0.5988754630088806\n",
      "Epoch 229, Loss: 0.5988754630088806\n",
      "Validation Loss: 0.6113746166229248\n",
      "Epoch 230, Loss: 0.6113746166229248\n",
      "Validation Loss: 0.6313196420669556\n",
      "Epoch 231, Loss: 0.6313196420669556\n",
      "Validation Loss: 0.5896368622779846\n",
      "Epoch 232, Loss: 0.5896368622779846\n",
      "Validation Loss: 0.6138408184051514\n",
      "Epoch 233, Loss: 0.6138408184051514\n",
      "Validation Loss: 0.588084876537323\n",
      "Epoch 234, Loss: 0.588084876537323\n",
      "Validation Loss: 0.636527955532074\n",
      "Epoch 235, Loss: 0.636527955532074\n",
      "Validation Loss: 0.6374779343605042\n",
      "Epoch 236, Loss: 0.6374779343605042\n",
      "Validation Loss: 0.6065415143966675\n",
      "Epoch 237, Loss: 0.6065415143966675\n",
      "Validation Loss: 0.6256933808326721\n",
      "Epoch 238, Loss: 0.6256933808326721\n",
      "Validation Loss: 0.6425718665122986\n",
      "Epoch 239, Loss: 0.6425718665122986\n",
      "Validation Loss: 0.6112969517707825\n",
      "Epoch 240, Loss: 0.6112969517707825\n",
      "Validation Loss: 0.619568407535553\n",
      "Epoch 241, Loss: 0.619568407535553\n",
      "Validation Loss: 0.6005471348762512\n",
      "Epoch 242, Loss: 0.6005471348762512\n",
      "Validation Loss: 0.5892206430435181\n",
      "Epoch 243, Loss: 0.5892206430435181\n",
      "Validation Loss: 0.6316016316413879\n",
      "Epoch 244, Loss: 0.6316016316413879\n",
      "Validation Loss: 0.5634074807167053\n",
      "Epoch 245, Loss: 0.5634074807167053\n",
      "Validation Loss: 0.5555394887924194\n",
      "Epoch 246, Loss: 0.5555394887924194\n",
      "Validation Loss: 0.5793095231056213\n",
      "Epoch 247, Loss: 0.5793095231056213\n",
      "Validation Loss: 0.5708830952644348\n",
      "Epoch 248, Loss: 0.5708830952644348\n",
      "Validation Loss: 0.5584778189659119\n",
      "Epoch 249, Loss: 0.5584778189659119\n",
      "Validation Loss: 0.5414246320724487\n",
      "Epoch 250, Loss: 0.5414246320724487\n",
      "Validation Loss: 0.5739996433258057\n",
      "Epoch 251, Loss: 0.5739996433258057\n",
      "Validation Loss: 0.5828289985656738\n",
      "Epoch 252, Loss: 0.5828289985656738\n",
      "Validation Loss: 0.5431280136108398\n",
      "Epoch 253, Loss: 0.5431280136108398\n",
      "Validation Loss: 0.5488718152046204\n",
      "Epoch 254, Loss: 0.5488718152046204\n",
      "Validation Loss: 0.5776267647743225\n",
      "Epoch 255, Loss: 0.5776267647743225\n",
      "Validation Loss: 0.5588911771774292\n",
      "Epoch 256, Loss: 0.5588911771774292\n",
      "Validation Loss: 0.5496416687965393\n",
      "Epoch 257, Loss: 0.5496416687965393\n",
      "Validation Loss: 0.5414325594902039\n",
      "Epoch 258, Loss: 0.5414325594902039\n",
      "Validation Loss: 0.5372971296310425\n",
      "Epoch 259, Loss: 0.5372971296310425\n",
      "Validation Loss: 0.5299109816551208\n",
      "Epoch 260, Loss: 0.5299109816551208\n",
      "Validation Loss: 0.5442659854888916\n",
      "Epoch 261, Loss: 0.5442659854888916\n",
      "Validation Loss: 0.5156172513961792\n",
      "Epoch 262, Loss: 0.5156172513961792\n",
      "Validation Loss: 0.5218103528022766\n",
      "Epoch 263, Loss: 0.5218103528022766\n",
      "Validation Loss: 0.5397419333457947\n",
      "Epoch 264, Loss: 0.5397419333457947\n",
      "Validation Loss: 0.5483191013336182\n",
      "Epoch 265, Loss: 0.5483191013336182\n",
      "Validation Loss: 0.5433021187782288\n",
      "Epoch 266, Loss: 0.5433021187782288\n",
      "Validation Loss: 0.5800431966781616\n",
      "Epoch 267, Loss: 0.5800431966781616\n",
      "Validation Loss: 0.5389060974121094\n",
      "Epoch 268, Loss: 0.5389060974121094\n",
      "Validation Loss: 0.5599448084831238\n",
      "Epoch 269, Loss: 0.5599448084831238\n",
      "Validation Loss: 0.563503623008728\n",
      "Epoch 270, Loss: 0.563503623008728\n",
      "Validation Loss: 0.5282936692237854\n",
      "Epoch 271, Loss: 0.5282936692237854\n",
      "Validation Loss: 0.5233374834060669\n",
      "Epoch 272, Loss: 0.5233374834060669\n",
      "Validation Loss: 0.5608596801757812\n",
      "Epoch 273, Loss: 0.5608596801757812\n",
      "Validation Loss: 0.5321799516677856\n",
      "Epoch 274, Loss: 0.5321799516677856\n",
      "Validation Loss: 0.5626459717750549\n",
      "Epoch 275, Loss: 0.5626459717750549\n",
      "Validation Loss: 0.5211833715438843\n",
      "Epoch 276, Loss: 0.5211833715438843\n",
      "Validation Loss: 0.5347729921340942\n",
      "Epoch 277, Loss: 0.5347729921340942\n",
      "Validation Loss: 0.5531995892524719\n",
      "Epoch 278, Loss: 0.5531995892524719\n",
      "Validation Loss: 0.5404521226882935\n",
      "Epoch 279, Loss: 0.5404521226882935\n",
      "Validation Loss: 0.5594630837440491\n",
      "Epoch 280, Loss: 0.5594630837440491\n",
      "Validation Loss: 0.5473616123199463\n",
      "Epoch 281, Loss: 0.5473616123199463\n",
      "Validation Loss: 0.5700810551643372\n",
      "Epoch 282, Loss: 0.5700810551643372\n",
      "Validation Loss: 0.5592625737190247\n",
      "Epoch 283, Loss: 0.5592625737190247\n",
      "Validation Loss: 0.573979914188385\n",
      "Epoch 284, Loss: 0.573979914188385\n",
      "Validation Loss: 0.5623403787612915\n",
      "Epoch 285, Loss: 0.5623403787612915\n",
      "Validation Loss: 0.6147624254226685\n",
      "Epoch 286, Loss: 0.6147624254226685\n",
      "Validation Loss: 0.5572522282600403\n",
      "Epoch 287, Loss: 0.5572522282600403\n",
      "Validation Loss: 0.5788078308105469\n",
      "Epoch 288, Loss: 0.5788078308105469\n",
      "Validation Loss: 0.5569703578948975\n",
      "Epoch 289, Loss: 0.5569703578948975\n",
      "Validation Loss: 0.5770213603973389\n",
      "Epoch 290, Loss: 0.5770213603973389\n",
      "Validation Loss: 0.5732938647270203\n",
      "Epoch 291, Loss: 0.5732938647270203\n",
      "Validation Loss: 0.5621147155761719\n",
      "Epoch 292, Loss: 0.5621147155761719\n",
      "Validation Loss: 0.5659560561180115\n",
      "Epoch 293, Loss: 0.5659560561180115\n",
      "Validation Loss: 0.5767672061920166\n",
      "Epoch 294, Loss: 0.5767672061920166\n",
      "Validation Loss: 0.5858662724494934\n",
      "Epoch 295, Loss: 0.5858662724494934\n",
      "Validation Loss: 0.574405312538147\n",
      "Epoch 296, Loss: 0.574405312538147\n",
      "Validation Loss: 0.5739258527755737\n",
      "Epoch 297, Loss: 0.5739258527755737\n",
      "Validation Loss: 0.5728682279586792\n",
      "Epoch 298, Loss: 0.5728682279586792\n",
      "Validation Loss: 0.5403497219085693\n",
      "Epoch 299, Loss: 0.5403497219085693\n",
      "Validation Loss: 0.5633012056350708\n",
      "Epoch 300, Loss: 0.5633012056350708\n",
      "Validation Loss: 0.5464641451835632\n",
      "Epoch 301, Loss: 0.5464641451835632\n",
      "Validation Loss: 0.5441130995750427\n",
      "Epoch 302, Loss: 0.5441130995750427\n",
      "Validation Loss: 0.5891193151473999\n",
      "Epoch 303, Loss: 0.5891193151473999\n",
      "Validation Loss: 0.5474537014961243\n",
      "Epoch 304, Loss: 0.5474537014961243\n",
      "Validation Loss: 0.5536335706710815\n",
      "Epoch 305, Loss: 0.5536335706710815\n",
      "Validation Loss: 0.5473349690437317\n",
      "Epoch 306, Loss: 0.5473349690437317\n",
      "Validation Loss: 0.5823478102684021\n",
      "Epoch 307, Loss: 0.5823478102684021\n",
      "Validation Loss: 0.53118497133255\n",
      "Epoch 308, Loss: 0.53118497133255\n",
      "Validation Loss: 0.5565348267555237\n",
      "Epoch 309, Loss: 0.5565348267555237\n",
      "Validation Loss: 0.5418674945831299\n",
      "Epoch 310, Loss: 0.5418674945831299\n",
      "Validation Loss: 0.5687676072120667\n",
      "Epoch 311, Loss: 0.5687676072120667\n",
      "Validation Loss: 0.5281431674957275\n",
      "Epoch 312, Loss: 0.5281431674957275\n",
      "Validation Loss: 0.5227169990539551\n",
      "Epoch 313, Loss: 0.5227169990539551\n",
      "Validation Loss: 0.5149819254875183\n",
      "Epoch 314, Loss: 0.5149819254875183\n",
      "Validation Loss: 0.5338577628135681\n",
      "Epoch 315, Loss: 0.5338577628135681\n",
      "Validation Loss: 0.5183005928993225\n",
      "Epoch 316, Loss: 0.5183005928993225\n",
      "Validation Loss: 0.5148569941520691\n",
      "Epoch 317, Loss: 0.5148569941520691\n",
      "Validation Loss: 0.5152391195297241\n",
      "Epoch 318, Loss: 0.5152391195297241\n",
      "Validation Loss: 0.5406369566917419\n",
      "Epoch 319, Loss: 0.5406369566917419\n",
      "Validation Loss: 0.5178626775741577\n",
      "Epoch 320, Loss: 0.5178626775741577\n",
      "Validation Loss: 0.5162758827209473\n",
      "Epoch 321, Loss: 0.5162758827209473\n",
      "Validation Loss: 0.5072153210639954\n",
      "Epoch 322, Loss: 0.5072153210639954\n",
      "Validation Loss: 0.52260422706604\n",
      "Epoch 323, Loss: 0.52260422706604\n",
      "Validation Loss: 0.5105534791946411\n",
      "Epoch 324, Loss: 0.5105534791946411\n",
      "Validation Loss: 0.5156897306442261\n",
      "Epoch 325, Loss: 0.5156897306442261\n",
      "Validation Loss: 0.5205041170120239\n",
      "Epoch 326, Loss: 0.5205041170120239\n",
      "Validation Loss: 0.5177174806594849\n",
      "Epoch 327, Loss: 0.5177174806594849\n",
      "Validation Loss: 0.5460978150367737\n",
      "Epoch 328, Loss: 0.5460978150367737\n",
      "Validation Loss: 0.5220568776130676\n",
      "Epoch 329, Loss: 0.5220568776130676\n",
      "Validation Loss: 0.5186448097229004\n",
      "Epoch 330, Loss: 0.5186448097229004\n",
      "Validation Loss: 0.5321802496910095\n",
      "Epoch 331, Loss: 0.5321802496910095\n",
      "Validation Loss: 0.5237694382667542\n",
      "Epoch 332, Loss: 0.5237694382667542\n",
      "Validation Loss: 0.5233511924743652\n",
      "Epoch 333, Loss: 0.5233511924743652\n",
      "Validation Loss: 0.5128476023674011\n",
      "Epoch 334, Loss: 0.5128476023674011\n",
      "Validation Loss: 0.5149394869804382\n",
      "Epoch 335, Loss: 0.5149394869804382\n",
      "Validation Loss: 0.5158858299255371\n",
      "Epoch 336, Loss: 0.5158858299255371\n",
      "Validation Loss: 0.5011873841285706\n",
      "Epoch 337, Loss: 0.5011873841285706\n",
      "Validation Loss: 0.5150375366210938\n",
      "Epoch 338, Loss: 0.5150375366210938\n",
      "Validation Loss: 0.4959641695022583\n",
      "Epoch 339, Loss: 0.4959641695022583\n",
      "Validation Loss: 0.5289292931556702\n",
      "Epoch 340, Loss: 0.5289292931556702\n",
      "Validation Loss: 0.5201051235198975\n",
      "Epoch 341, Loss: 0.5201051235198975\n",
      "Validation Loss: 0.5223932266235352\n",
      "Epoch 342, Loss: 0.5223932266235352\n",
      "Validation Loss: 0.5386583209037781\n",
      "Epoch 343, Loss: 0.5386583209037781\n",
      "Validation Loss: 0.5147813558578491\n",
      "Epoch 344, Loss: 0.5147813558578491\n",
      "Validation Loss: 0.518161952495575\n",
      "Epoch 345, Loss: 0.518161952495575\n",
      "Validation Loss: 0.537137508392334\n",
      "Epoch 346, Loss: 0.537137508392334\n",
      "Validation Loss: 0.5049009919166565\n",
      "Epoch 347, Loss: 0.5049009919166565\n",
      "Validation Loss: 0.5064783096313477\n",
      "Epoch 348, Loss: 0.5064783096313477\n",
      "Validation Loss: 0.5223250389099121\n",
      "Epoch 349, Loss: 0.5223250389099121\n",
      "Validation Loss: 0.5078802108764648\n",
      "Epoch 350, Loss: 0.5078802108764648\n",
      "Validation Loss: 0.5297950506210327\n",
      "Epoch 351, Loss: 0.5297950506210327\n",
      "Validation Loss: 0.501386284828186\n",
      "Epoch 352, Loss: 0.501386284828186\n",
      "Validation Loss: 0.5054822564125061\n",
      "Epoch 353, Loss: 0.5054822564125061\n",
      "Validation Loss: 0.4895438253879547\n",
      "Epoch 354, Loss: 0.4895438253879547\n",
      "Validation Loss: 0.486848920583725\n",
      "Epoch 355, Loss: 0.486848920583725\n",
      "Validation Loss: 0.5208401083946228\n",
      "Epoch 356, Loss: 0.5208401083946228\n",
      "Validation Loss: 0.48693379759788513\n",
      "Epoch 357, Loss: 0.48693379759788513\n",
      "Validation Loss: 0.4837036728858948\n",
      "Epoch 358, Loss: 0.4837036728858948\n",
      "Validation Loss: 0.4803990125656128\n",
      "Epoch 359, Loss: 0.4803990125656128\n",
      "Validation Loss: 0.5094449520111084\n",
      "Epoch 360, Loss: 0.5094449520111084\n",
      "Validation Loss: 0.48271504044532776\n",
      "Epoch 361, Loss: 0.48271504044532776\n",
      "Validation Loss: 0.49344515800476074\n",
      "Epoch 362, Loss: 0.49344515800476074\n",
      "Validation Loss: 0.4726329445838928\n",
      "Epoch 363, Loss: 0.4726329445838928\n",
      "Validation Loss: 0.4823857247829437\n",
      "Epoch 364, Loss: 0.4823857247829437\n",
      "Validation Loss: 0.4839456081390381\n",
      "Epoch 365, Loss: 0.4839456081390381\n",
      "Validation Loss: 0.4674800932407379\n",
      "Epoch 366, Loss: 0.4674800932407379\n",
      "Validation Loss: 0.45069414377212524\n",
      "Epoch 367, Loss: 0.45069414377212524\n",
      "Validation Loss: 0.4537831246852875\n",
      "Epoch 368, Loss: 0.4537831246852875\n",
      "Validation Loss: 0.4538685381412506\n",
      "Epoch 369, Loss: 0.4538685381412506\n",
      "Validation Loss: 0.4638316035270691\n",
      "Epoch 370, Loss: 0.4638316035270691\n",
      "Validation Loss: 0.45952108502388\n",
      "Epoch 371, Loss: 0.45952108502388\n",
      "Validation Loss: 0.4675501585006714\n",
      "Epoch 372, Loss: 0.4675501585006714\n",
      "Validation Loss: 0.44924914836883545\n",
      "Epoch 373, Loss: 0.44924914836883545\n",
      "Validation Loss: 0.47341591119766235\n",
      "Epoch 374, Loss: 0.47341591119766235\n",
      "Validation Loss: 0.4519261121749878\n",
      "Epoch 375, Loss: 0.4519261121749878\n",
      "Validation Loss: 0.4749148488044739\n",
      "Epoch 376, Loss: 0.4749148488044739\n",
      "Validation Loss: 0.4692053496837616\n",
      "Epoch 377, Loss: 0.4692053496837616\n",
      "Validation Loss: 0.4563254714012146\n",
      "Epoch 378, Loss: 0.4563254714012146\n",
      "Validation Loss: 0.45353221893310547\n",
      "Epoch 379, Loss: 0.45353221893310547\n",
      "Validation Loss: 0.44789373874664307\n",
      "Epoch 380, Loss: 0.44789373874664307\n",
      "Validation Loss: 0.4484612047672272\n",
      "Epoch 381, Loss: 0.4484612047672272\n",
      "Validation Loss: 0.46271005272865295\n",
      "Epoch 382, Loss: 0.46271005272865295\n",
      "Validation Loss: 0.46392562985420227\n",
      "Epoch 383, Loss: 0.46392562985420227\n",
      "Validation Loss: 0.4686192572116852\n",
      "Epoch 384, Loss: 0.4686192572116852\n",
      "Validation Loss: 0.47496941685676575\n",
      "Epoch 385, Loss: 0.47496941685676575\n",
      "Validation Loss: 0.4656355679035187\n",
      "Epoch 386, Loss: 0.4656355679035187\n",
      "Validation Loss: 0.45261770486831665\n",
      "Epoch 387, Loss: 0.45261770486831665\n",
      "Validation Loss: 0.42806771397590637\n",
      "Epoch 388, Loss: 0.42806771397590637\n",
      "Validation Loss: 0.43091416358947754\n",
      "Epoch 389, Loss: 0.43091416358947754\n",
      "Validation Loss: 0.4211772382259369\n",
      "Epoch 390, Loss: 0.4211772382259369\n",
      "Validation Loss: 0.4243152141571045\n",
      "Epoch 391, Loss: 0.4243152141571045\n",
      "Validation Loss: 0.43393030762672424\n",
      "Epoch 392, Loss: 0.43393030762672424\n",
      "Validation Loss: 0.4229094684123993\n",
      "Epoch 393, Loss: 0.4229094684123993\n",
      "Validation Loss: 0.42681336402893066\n",
      "Epoch 394, Loss: 0.42681336402893066\n",
      "Validation Loss: 0.42754995822906494\n",
      "Epoch 395, Loss: 0.42754995822906494\n",
      "Validation Loss: 0.41787880659103394\n",
      "Epoch 396, Loss: 0.41787880659103394\n",
      "Validation Loss: 0.4245768189430237\n",
      "Epoch 397, Loss: 0.4245768189430237\n",
      "Validation Loss: 0.4176836907863617\n",
      "Epoch 398, Loss: 0.4176836907863617\n",
      "Validation Loss: 0.41406676173210144\n",
      "Epoch 399, Loss: 0.41406676173210144\n",
      "Validation Loss: 0.42042481899261475\n",
      "Epoch 400, Loss: 0.42042481899261475\n",
      "Validation Loss: 0.4199264347553253\n",
      "Epoch 401, Loss: 0.4199264347553253\n",
      "Validation Loss: 0.4417574405670166\n",
      "Epoch 402, Loss: 0.4417574405670166\n",
      "Validation Loss: 0.4111648499965668\n",
      "Epoch 403, Loss: 0.4111648499965668\n",
      "Validation Loss: 0.4204312860965729\n",
      "Epoch 404, Loss: 0.4204312860965729\n",
      "Validation Loss: 0.40854108333587646\n",
      "Epoch 405, Loss: 0.40854108333587646\n",
      "Validation Loss: 0.41195210814476013\n",
      "Epoch 406, Loss: 0.41195210814476013\n",
      "Validation Loss: 0.3863638639450073\n",
      "Epoch 407, Loss: 0.3863638639450073\n",
      "Validation Loss: 0.4144078195095062\n",
      "Epoch 408, Loss: 0.4144078195095062\n",
      "Validation Loss: 0.3856382369995117\n",
      "Epoch 409, Loss: 0.3856382369995117\n",
      "Validation Loss: 0.39208880066871643\n",
      "Epoch 410, Loss: 0.39208880066871643\n",
      "Validation Loss: 0.3890554904937744\n",
      "Epoch 411, Loss: 0.3890554904937744\n",
      "Validation Loss: 0.42636093497276306\n",
      "Epoch 412, Loss: 0.42636093497276306\n",
      "Validation Loss: 0.3948562741279602\n",
      "Epoch 413, Loss: 0.3948562741279602\n",
      "Validation Loss: 0.4142058491706848\n",
      "Epoch 414, Loss: 0.4142058491706848\n",
      "Validation Loss: 0.43577030301094055\n",
      "Epoch 415, Loss: 0.43577030301094055\n",
      "Validation Loss: 0.4088740348815918\n",
      "Epoch 416, Loss: 0.4088740348815918\n",
      "Validation Loss: 0.4209277331829071\n",
      "Epoch 417, Loss: 0.4209277331829071\n",
      "Validation Loss: 0.4164506494998932\n",
      "Epoch 418, Loss: 0.4164506494998932\n",
      "Validation Loss: 0.41202297806739807\n",
      "Epoch 419, Loss: 0.41202297806739807\n",
      "Validation Loss: 0.42821016907691956\n",
      "Epoch 420, Loss: 0.42821016907691956\n",
      "Validation Loss: 0.41458970308303833\n",
      "Epoch 421, Loss: 0.41458970308303833\n",
      "Validation Loss: 0.43835386633872986\n",
      "Epoch 422, Loss: 0.43835386633872986\n",
      "Validation Loss: 0.4354116916656494\n",
      "Epoch 423, Loss: 0.4354116916656494\n",
      "Validation Loss: 0.4353613555431366\n",
      "Epoch 424, Loss: 0.4353613555431366\n",
      "Validation Loss: 0.4356135427951813\n",
      "Epoch 425, Loss: 0.4356135427951813\n",
      "Validation Loss: 0.4441685974597931\n",
      "Epoch 426, Loss: 0.4441685974597931\n",
      "Validation Loss: 0.426721453666687\n",
      "Epoch 427, Loss: 0.426721453666687\n",
      "Validation Loss: 0.42444273829460144\n",
      "Epoch 428, Loss: 0.42444273829460144\n",
      "Validation Loss: 0.40913280844688416\n",
      "Epoch 429, Loss: 0.40913280844688416\n",
      "Validation Loss: 0.3913588225841522\n",
      "Epoch 430, Loss: 0.3913588225841522\n",
      "Validation Loss: 0.3801068067550659\n",
      "Epoch 431, Loss: 0.3801068067550659\n",
      "Validation Loss: 0.40915820002555847\n",
      "Epoch 432, Loss: 0.40915820002555847\n",
      "Validation Loss: 0.36919429898262024\n",
      "Epoch 433, Loss: 0.36919429898262024\n",
      "Validation Loss: 0.37576043605804443\n",
      "Epoch 434, Loss: 0.37576043605804443\n",
      "Validation Loss: 0.36107322573661804\n",
      "Epoch 435, Loss: 0.36107322573661804\n",
      "Validation Loss: 0.3996593654155731\n",
      "Epoch 436, Loss: 0.3996593654155731\n",
      "Validation Loss: 0.3736582100391388\n",
      "Epoch 437, Loss: 0.3736582100391388\n",
      "Validation Loss: 0.36736658215522766\n",
      "Epoch 438, Loss: 0.36736658215522766\n",
      "Validation Loss: 0.38259631395339966\n",
      "Epoch 439, Loss: 0.38259631395339966\n",
      "Validation Loss: 0.3791514039039612\n",
      "Epoch 440, Loss: 0.3791514039039612\n",
      "Validation Loss: 0.3607010543346405\n",
      "Epoch 441, Loss: 0.3607010543346405\n",
      "Validation Loss: 0.3844909965991974\n",
      "Epoch 442, Loss: 0.3844909965991974\n",
      "Validation Loss: 0.37379562854766846\n",
      "Epoch 443, Loss: 0.37379562854766846\n",
      "Validation Loss: 0.3853679299354553\n",
      "Epoch 444, Loss: 0.3853679299354553\n",
      "Validation Loss: 0.38276010751724243\n",
      "Epoch 445, Loss: 0.38276010751724243\n",
      "Validation Loss: 0.3796728849411011\n",
      "Epoch 446, Loss: 0.3796728849411011\n",
      "Validation Loss: 0.39062026143074036\n",
      "Epoch 447, Loss: 0.39062026143074036\n",
      "Validation Loss: 0.38980787992477417\n",
      "Epoch 448, Loss: 0.38980787992477417\n",
      "Validation Loss: 0.38671767711639404\n",
      "Epoch 449, Loss: 0.38671767711639404\n",
      "Validation Loss: 0.38512492179870605\n",
      "Epoch 450, Loss: 0.38512492179870605\n",
      "Validation Loss: 0.3695920407772064\n",
      "Epoch 451, Loss: 0.3695920407772064\n",
      "Validation Loss: 0.38871434330940247\n",
      "Epoch 452, Loss: 0.38871434330940247\n",
      "Validation Loss: 0.35832899808883667\n",
      "Epoch 453, Loss: 0.35832899808883667\n",
      "Validation Loss: 0.370072603225708\n",
      "Epoch 454, Loss: 0.370072603225708\n",
      "Validation Loss: 0.3711545467376709\n",
      "Epoch 455, Loss: 0.3711545467376709\n",
      "Validation Loss: 0.3693057894706726\n",
      "Epoch 456, Loss: 0.3693057894706726\n",
      "Validation Loss: 0.375214546918869\n",
      "Epoch 457, Loss: 0.375214546918869\n",
      "Validation Loss: 0.36199113726615906\n",
      "Epoch 458, Loss: 0.36199113726615906\n",
      "Validation Loss: 0.36635926365852356\n",
      "Epoch 459, Loss: 0.36635926365852356\n",
      "Validation Loss: 0.3914901912212372\n",
      "Epoch 460, Loss: 0.3914901912212372\n",
      "Validation Loss: 0.3711024522781372\n",
      "Epoch 461, Loss: 0.3711024522781372\n",
      "Validation Loss: 0.3762499988079071\n",
      "Epoch 462, Loss: 0.3762499988079071\n",
      "Validation Loss: 0.4063299298286438\n",
      "Epoch 463, Loss: 0.4063299298286438\n",
      "Validation Loss: 0.38829663395881653\n",
      "Epoch 464, Loss: 0.38829663395881653\n",
      "Validation Loss: 0.3865184783935547\n",
      "Epoch 465, Loss: 0.3865184783935547\n",
      "Validation Loss: 0.3914884328842163\n",
      "Epoch 466, Loss: 0.3914884328842163\n",
      "Validation Loss: 0.37770143151283264\n",
      "Epoch 467, Loss: 0.37770143151283264\n",
      "Validation Loss: 0.3758116662502289\n",
      "Epoch 468, Loss: 0.3758116662502289\n",
      "Validation Loss: 0.3638863265514374\n",
      "Epoch 469, Loss: 0.3638863265514374\n",
      "Validation Loss: 0.35980185866355896\n",
      "Epoch 470, Loss: 0.35980185866355896\n",
      "Validation Loss: 0.36431884765625\n",
      "Epoch 471, Loss: 0.36431884765625\n",
      "Validation Loss: 0.33854883909225464\n",
      "Epoch 472, Loss: 0.33854883909225464\n",
      "Validation Loss: 0.3611539304256439\n",
      "Epoch 473, Loss: 0.3611539304256439\n",
      "Validation Loss: 0.3546997308731079\n",
      "Epoch 474, Loss: 0.3546997308731079\n",
      "Validation Loss: 0.35956427454948425\n",
      "Epoch 475, Loss: 0.35956427454948425\n",
      "Validation Loss: 0.356829434633255\n",
      "Epoch 476, Loss: 0.356829434633255\n",
      "Validation Loss: 0.36522382497787476\n",
      "Epoch 477, Loss: 0.36522382497787476\n",
      "Validation Loss: 0.35293668508529663\n",
      "Epoch 478, Loss: 0.35293668508529663\n",
      "Validation Loss: 0.355356365442276\n",
      "Epoch 479, Loss: 0.355356365442276\n",
      "Validation Loss: 0.3327018916606903\n",
      "Epoch 480, Loss: 0.3327018916606903\n",
      "Validation Loss: 0.35253894329071045\n",
      "Epoch 481, Loss: 0.35253894329071045\n",
      "Validation Loss: 0.3324073553085327\n",
      "Epoch 482, Loss: 0.3324073553085327\n",
      "Validation Loss: 0.3467020094394684\n",
      "Epoch 483, Loss: 0.3467020094394684\n",
      "Validation Loss: 0.3408367931842804\n",
      "Epoch 484, Loss: 0.3408367931842804\n",
      "Validation Loss: 0.34442374110221863\n",
      "Epoch 485, Loss: 0.34442374110221863\n",
      "Validation Loss: 0.33447661995887756\n",
      "Epoch 486, Loss: 0.33447661995887756\n",
      "Validation Loss: 0.3449159860610962\n",
      "Epoch 487, Loss: 0.3449159860610962\n",
      "Validation Loss: 0.3632967472076416\n",
      "Epoch 488, Loss: 0.3632967472076416\n",
      "Validation Loss: 0.3520984649658203\n",
      "Epoch 489, Loss: 0.3520984649658203\n",
      "Validation Loss: 0.3603009879589081\n",
      "Epoch 490, Loss: 0.3603009879589081\n",
      "Validation Loss: 0.3496011197566986\n",
      "Epoch 491, Loss: 0.3496011197566986\n",
      "Validation Loss: 0.33715689182281494\n",
      "Epoch 492, Loss: 0.33715689182281494\n",
      "Validation Loss: 0.34953927993774414\n",
      "Epoch 493, Loss: 0.34953927993774414\n",
      "Validation Loss: 0.3426942229270935\n",
      "Epoch 494, Loss: 0.3426942229270935\n",
      "Validation Loss: 0.3392031490802765\n",
      "Epoch 495, Loss: 0.3392031490802765\n",
      "Validation Loss: 0.3138850927352905\n",
      "Epoch 496, Loss: 0.3138850927352905\n",
      "Validation Loss: 0.3153739869594574\n",
      "Epoch 497, Loss: 0.3153739869594574\n",
      "Validation Loss: 0.3149724006652832\n",
      "Epoch 498, Loss: 0.3149724006652832\n",
      "Validation Loss: 0.31081444025039673\n",
      "Epoch 499, Loss: 0.31081444025039673\n",
      "Validation Loss: 0.30733174085617065\n",
      "Epoch 500, Loss: 0.30733174085617065\n",
      "Validation Loss: 0.29224178194999695\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import RGCNConv\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=0.001)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(500):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    out = model(train_data.x_dict, train_data.edge_index_dict)\n",
    "    loss = criterion(out['recipe'], train_data['recipe'].y.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
    "    \n",
    "        # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "    \n",
    "        out = model(val_data.x_dict, val_data.edge_index_dict)\n",
    "        loss = criterion(out[\"recipe\"], val_data[\"recipe\"].y)\n",
    "        val_loss += loss.item()\n",
    "        print(f\"Validation Loss: {val_loss}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:23:50.379617500Z",
     "start_time": "2023-10-19T12:22:24.166411200Z"
    }
   },
   "id": "f332b1ab2bdecc74"
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2922382652759552\n",
      "F1 Score: 0.1896095301125083\n",
      "Precision: 0.32855504587155965\n",
      "Recall: 0.13325581395348837\n",
      "Accuracy: 0.25311203319502074\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# For evaluation metrics, you can use sklearn's metrics\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "# Convert the model's output to binary labels\n",
    "def to_binary_labels(output):\n",
    "    return (torch.sigmoid(output) > 0.5).int()\n",
    "\n",
    "# Evaluate on validation set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  # Assuming val_data is your validation data\n",
    "    out = model(test_data.x_dict, test_data.edge_index_dict)\n",
    "    test_loss = criterion(out['recipe'], test_data['recipe'].y.float())\n",
    "    print(f\"Test Loss: {test_loss.item()}\")\n",
    "\n",
    "    # Convert outputs to binary labels for metric calculation\n",
    "    preds = to_binary_labels(out['recipe'])\n",
    "    labels = test_data['recipe'].y.int()\n",
    "\n",
    "    f1 = f1_score(labels.numpy(), preds.numpy(), average='micro')\n",
    "    precision = precision_score(labels.numpy(), preds.numpy(), average='micro')\n",
    "    recall = recall_score(labels.numpy(), preds.numpy(), average='micro')\n",
    "    accuracy = accuracy_score(labels.numpy(), preds.numpy())\n",
    "\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"Accuracy: {accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:23:58.570593900Z",
     "start_time": "2023-10-19T12:23:58.206628900Z"
    }
   },
   "id": "887039b8df14d594"
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "                               recipeId  \\\n0  a220a04a-c211-461d-bad8-d73ed2d29ea3   \n1  cbf082fa-38b1-4395-b3a7-0a0546333861   \n2  1dd265fa-d7d0-408f-9ab3-bcf42d66211d   \n3  42aaa6ff-eaf8-4c1b-8925-55e245a56678   \n4  67902641-b348-45f2-b8dd-bee9a3070c9e   \n\n                                   title  \\\n0                       Baked feta pasta   \n1  Blomklsuppe med kikerter og grnnkl   \n2       Blomklsalat med syrlig dressing   \n3                       Steinsopprisotto   \n4               Klassisk pasta carbonara   \n\n                                           embedding  \n0  [-0.0077616022899746895, -0.007513688877224922...  \n1  [-0.005160760134458542, -0.020936481654644012,...  \n2  [-0.017495296895503998, -0.019598836079239845,...  \n3  [0.0018266895785927773, -0.029227033257484436,...  \n4  [0.0034193696919828653, -0.01366486120969057, ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>recipeId</th>\n      <th>title</th>\n      <th>embedding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a220a04a-c211-461d-bad8-d73ed2d29ea3</td>\n      <td>Baked feta pasta</td>\n      <td>[-0.0077616022899746895, -0.007513688877224922...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>cbf082fa-38b1-4395-b3a7-0a0546333861</td>\n      <td>Blomklsuppe med kikerter og grnnkl</td>\n      <td>[-0.005160760134458542, -0.020936481654644012,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1dd265fa-d7d0-408f-9ab3-bcf42d66211d</td>\n      <td>Blomklsalat med syrlig dressing</td>\n      <td>[-0.017495296895503998, -0.019598836079239845,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>42aaa6ff-eaf8-4c1b-8925-55e245a56678</td>\n      <td>Steinsopprisotto</td>\n      <td>[0.0018266895785927773, -0.029227033257484436,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>67902641-b348-45f2-b8dd-bee9a3070c9e</td>\n      <td>Klassisk pasta carbonara</td>\n      <td>[0.0034193696919828653, -0.01366486120969057, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_tag_query = \"\"\"\n",
    "MATCH (n:Recipe)\n",
    "WHERE NOT (n)-[:HAS_TAG]->(:Tag)\n",
    "return n.recipieId as recipeId, n.title as title, n.openaiEmbeddings as embedding\n",
    "\"\"\" \n",
    "\n",
    "df = fetch_data(no_tag_query)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:28:22.011993900Z",
     "start_time": "2023-10-19T12:28:19.990815300Z"
    }
   },
   "id": "6d2f2f91d3d48b47"
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eirik\\AppData\\Local\\Temp\\ipykernel_5568\\1967023764.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  \"embedding\": lambda x: torch.Tensor(x)\n"
     ]
    }
   ],
   "source": [
    "recipe_x, recipe_mapping, _ = load_node(\n",
    "    no_tag_query, \n",
    "    index_col='recipeId', \n",
    "    encoders={\n",
    "        \"embedding\": lambda x: torch.Tensor(x)\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:30:25.019637400Z",
     "start_time": "2023-10-19T12:30:23.185751800Z"
    }
   },
   "id": "659541949b2acb08"
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([183, 1536]), 183)"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_x.shape, len(recipe_mapping)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:30:37.864367500Z",
     "start_time": "2023-10-19T12:30:37.708115700Z"
    }
   },
   "id": "65149e3fad1cdf50"
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "recipe_menu_query = \"\"\"\n",
    "MATCH (n:Recipe)-[r:IS_PART_OF_MENU]->(m:Menu)\n",
    "WHERE NOT (n)-[:HAS_TAG]->(:Tag)\n",
    "RETURN DISTINCT n.recipieId AS recipeId, ID(m) AS menuId, r.weekDay AS weekDay\n",
    "\"\"\"\n",
    "\n",
    "recipe_menu_edge_index, recipe_menu_edge_label = load_edge(\n",
    "    recipe_menu_query,\n",
    "    src_index_col='recipeId',\n",
    "    src_mapping=recipe_mapping,\n",
    "    dst_index_col='menuId',\n",
    "    dst_mapping=menu_mapping,\n",
    "    encoders={'weekDay': WeekdayEncoder()},\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:31:20.007068700Z",
     "start_time": "2023-10-19T12:31:19.577676Z"
    }
   },
   "id": "23b63b1ecc9f21ed"
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([2, 295]), torch.Size([295, 7]))"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_menu_edge_index.shape, recipe_menu_edge_label.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:31:34.113565Z",
     "start_time": "2023-10-19T12:31:33.957312Z"
    }
   },
   "id": "fcf719fd06f8cbfc"
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "recipe_ingredient_query = \"\"\"\n",
    "MATCH (n)-[r:HAS_INGREDIENT]->(i:Ingredient)\n",
    "WHERE NOT (n)-[:HAS_TAG]->(:Tag)\n",
    "RETURN DISTINCT n.recipieId AS recipeId, ID(i) AS ingredientId\n",
    "\"\"\"\n",
    "\n",
    "recipe_ingredient_edge_index, recipe_ingredient_edge_label = load_edge(\n",
    "    recipe_ingredient_query,\n",
    "    src_index_col='recipeId',\n",
    "    src_mapping=recipe_mapping,\n",
    "    dst_index_col='ingredientId',\n",
    "    dst_mapping=ingredient_mapping,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:32:00.374943100Z",
     "start_time": "2023-10-19T12:31:59.964958600Z"
    }
   },
   "id": "70c9f894136ef3f7"
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([2, 1986]), None)"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_ingredient_edge_index.shape, recipe_ingredient_edge_label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:32:03.802772200Z",
     "start_time": "2023-10-19T12:32:03.693396800Z"
    }
   },
   "id": "1e7206d4a30ee227"
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "data": {
      "text/plain": "HeteroData(\n  num_relations=2,\n  num_nodes=2118,\n  recipe={ x=[183, 1536] },\n  menu={ x=[142, 2] },\n  ingredient={ x=[1793, 384] },\n  (recipe, has_ingredient, ingredient)={ edge_index=[2, 1986] },\n  (recipe, is_part_of_menu, menu)={\n    edge_index=[2, 295],\n    edge_attr=[295, 7],\n  }\n)"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "no_tag_data = HeteroData()\n",
    "\n",
    "no_tag_data['recipe'].x = recipe_x\n",
    "no_tag_data[\"menu\"].x = menu_x\n",
    "no_tag_data[\"ingredient\"].x = ingredient_x\n",
    "no_tag_data[\"recipe\", \"has_ingredient\", \"ingredient\"].edge_index = recipe_ingredient_edge_index\n",
    "no_tag_data[\"recipe\", \"is_part_of_menu\", \"menu\"].edge_index = recipe_menu_edge_index\n",
    "no_tag_data[\"recipe\", \"is_part_of_menu\", \"menu\"].edge_attr = recipe_menu_edge_label\n",
    "no_tag_data.num_relations = 2\n",
    "no_tag_data.num_nodes = len(recipe_mapping) + len(ingredient_mapping) + len(menu_mapping)\n",
    "no_tag_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:33:04.640623400Z",
     "start_time": "2023-10-19T12:33:04.484372900Z"
    }
   },
   "id": "9022541273d4e587"
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "data": {
      "text/plain": "HeteroData(\n  num_relations=2,\n  num_nodes=2118,\n  recipe={ x=[183, 1536] },\n  menu={ x=[142, 2] },\n  ingredient={ x=[1793, 384] },\n  (recipe, has_ingredient, ingredient)={ edge_index=[2, 1986] },\n  (recipe, is_part_of_menu, menu)={\n    edge_index=[2, 295],\n    edge_attr=[295, 7],\n  },\n  (ingredient, rev_has_ingredient, recipe)={ edge_index=[2, 1986] },\n  (menu, rev_is_part_of_menu, recipe)={\n    edge_index=[2, 295],\n    edge_attr=[295, 7],\n  }\n)"
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.transforms import ToUndirected\n",
    "\n",
    "no_tag_data = ToUndirected()(no_tag_data)\n",
    "no_tag_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:33:26.587056700Z",
     "start_time": "2023-10-19T12:33:26.383928500Z"
    }
   },
   "id": "22b8de7036ee695e"
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Assuming test_data is your filtered data without tags\n",
    "    out = model(no_tag_data.x_dict, no_tag_data.edge_index_dict)\n",
    "    \n",
    "    # Convert outputs to probabilities\n",
    "    probs = torch.sigmoid(out['recipe'])\n",
    "    \n",
    "    # Convert probabilities to binary labels (if needed)\n",
    "    preds = (probs > 0.5).int()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:34:00.747509700Z",
     "start_time": "2023-10-19T12:34:00.480675400Z"
    }
   },
   "id": "ac2574b47720c5e2"
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]])"
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:45:15.700520500Z",
     "start_time": "2023-10-19T12:45:15.601135500Z"
    }
   },
   "id": "387f9ad6956e0979"
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "df = fetch_data(no_tag_query)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:49:29.157284500Z",
     "start_time": "2023-10-19T12:49:27.632195400Z"
    }
   },
   "id": "126e89d2e3574fa3"
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262\n",
      "262\n",
      "183\n"
     ]
    }
   ],
   "source": [
    "print(len(mlb.classes_))\n",
    "print(len(preds[0]))\n",
    "print(len(df))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:49:30.661463400Z",
     "start_time": "2023-10-19T12:49:30.536461900Z"
    }
   },
   "id": "46951f77e84d4709"
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "data": {
      "text/plain": "                                     title  \\\n0                         Baked feta pasta   \n1    Blomklsuppe med kikerter og grnnkl   \n2         Blomklsalat med syrlig dressing   \n3                         Steinsopprisotto   \n4                 Klassisk pasta carbonara   \n..                                     ...   \n178                             Lam i pita   \n179               Quinoasalat med gresskar   \n180                   Enkel grnnsakssuppe   \n181      Middagssalat med kikerter og feta   \n182       Enkel middelhavspasta med oliven   \n\n                                                  tags  \n0                       (Hovedrett, Skalldyr, Tex-Mex)  \n1                       (Hovedrett, Skalldyr, Tex-Mex)  \n2                       (Hovedrett, Skalldyr, Tex-Mex)  \n3    (Forrett, Gjester, Hovedrett, Skalldyr, Sushi,...  \n4                         (Hovedrett, Kylling, Sommer)  \n..                                                 ...  \n178                                     (Middagstips,)  \n179  (Forrett, Gjester, Hovedrett, Skalldyr, Sushi,...  \n180                       (Hovedrett, Kylling, Sommer)  \n181                     (Hovedrett, Skalldyr, Tex-Mex)  \n182                               (Hovedrett, Tex-Mex)  \n\n[183 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Baked feta pasta</td>\n      <td>(Hovedrett, Skalldyr, Tex-Mex)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Blomklsuppe med kikerter og grnnkl</td>\n      <td>(Hovedrett, Skalldyr, Tex-Mex)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Blomklsalat med syrlig dressing</td>\n      <td>(Hovedrett, Skalldyr, Tex-Mex)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Steinsopprisotto</td>\n      <td>(Forrett, Gjester, Hovedrett, Skalldyr, Sushi,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Klassisk pasta carbonara</td>\n      <td>(Hovedrett, Kylling, Sommer)</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>178</th>\n      <td>Lam i pita</td>\n      <td>(Middagstips,)</td>\n    </tr>\n    <tr>\n      <th>179</th>\n      <td>Quinoasalat med gresskar</td>\n      <td>(Forrett, Gjester, Hovedrett, Skalldyr, Sushi,...</td>\n    </tr>\n    <tr>\n      <th>180</th>\n      <td>Enkel grnnsakssuppe</td>\n      <td>(Hovedrett, Kylling, Sommer)</td>\n    </tr>\n    <tr>\n      <th>181</th>\n      <td>Middagssalat med kikerter og feta</td>\n      <td>(Hovedrett, Skalldyr, Tex-Mex)</td>\n    </tr>\n    <tr>\n      <th>182</th>\n      <td>Enkel middelhavspasta med oliven</td>\n      <td>(Hovedrett, Tex-Mex)</td>\n    </tr>\n  </tbody>\n</table>\n<p>183 rows  2 columns</p>\n</div>"
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"tags\"] = mlb.inverse_transform(preds.numpy())\n",
    "df[[\"title\", \"tags\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:49:48.401240200Z",
     "start_time": "2023-10-19T12:49:48.275663700Z"
    }
   },
   "id": "8b601b980dccc3bd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
