{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-17T11:02:18.724801300Z",
     "start_time": "2023-10-17T11:00:33.077389700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# Install necessary dependencies (takes a long time)\n",
    "!pip install torch torch_scatter torch_sparse torch_geometric graphdatascience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from graphdatascience import GraphDataScience\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, RGCNConv\n",
    "from torch_geometric.transforms import RandomNodeSplit\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T11:50:02.611869100Z",
     "start_time": "2023-10-19T11:50:02.580619400Z"
    }
   },
   "id": "7433ca089de8e0b8"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Set seeds for consistent results\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T11:50:04.072151900Z",
     "start_time": "2023-10-19T11:50:04.009651Z"
    }
   },
   "id": "558506b8a770ba8c"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Get Neo4j DB URI, credentials and name from environment if applicable\n",
    "NEO4J_URI = os.environ.get(\"NEO4J_URI\", \"bolt://localhost:7687\")\n",
    "NEO4J_DB = os.environ.get(\"NEO4J_DB\", \"neo4j\")\n",
    "NEO4J_AUTH = (\n",
    "    os.environ.get(\"NEO4J_USER\", \"neo4j\"),\n",
    "    os.environ.get(\"NEO4J_PASSWORD\", \"pleaseletmein\"),\n",
    ")\n",
    "\n",
    "gds = GraphDataScience(NEO4J_URI, auth=NEO4J_AUTH, database=NEO4J_DB)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T11:50:05.938302Z",
     "start_time": "2023-10-19T11:50:05.755077700Z"
    }
   },
   "id": "ddd8d22b7a587458"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def fetch_data(query):\n",
    "    return gds.run_cypher(query)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T11:50:08.936546400Z",
     "start_time": "2023-10-19T11:50:08.920924100Z"
    }
   },
   "id": "d6939e21a13c7fa2"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def load_node(cypher, index_col, encoders=None, target_encoders=None, **kwargs):\n",
    "    # Execute the cypher query and retrieve data from Neo4j\n",
    "    df = fetch_data(cypher)\n",
    "    df.set_index(index_col, inplace=True)\n",
    "    # Define node mapping\n",
    "    mapping = {index: i for i, index in enumerate(df.index.unique())}\n",
    "    # Define node features\n",
    "    x = None\n",
    "    if encoders is not None:\n",
    "        xs = [encoder(df[col]) for col, encoder in encoders.items()]\n",
    "        x = torch.cat(xs, dim=-1)\n",
    "        \n",
    "    y = None\n",
    "    if target_encoders is not None: \n",
    "        ys = [encoder(df[col]) for col, encoder in target_encoders.items()]\n",
    "        y = torch.cat(ys, dim=-1)\n",
    "\n",
    "    return x, mapping, y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T11:50:27.041355400Z",
     "start_time": "2023-10-19T11:50:26.588241100Z"
    }
   },
   "id": "82393231c3d732ab"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def load_edge(cypher, src_index_col, src_mapping, dst_index_col, dst_mapping,\n",
    "                  encoders=None, **kwargs):\n",
    "    # Execute the cypher query and retrieve data from Neo4j\n",
    "    df = fetch_data(cypher)\n",
    "    # Define edge index\n",
    "    src = [src_mapping[index] for index in df[src_index_col]]\n",
    "    dst = [dst_mapping[index] for index in df[dst_index_col]]\n",
    "    edge_index = torch.tensor([src, dst])\n",
    "    # Define edge features\n",
    "    edge_attr = None\n",
    "    if encoders is not None:\n",
    "        edge_attrs = [encoder(df[col]) for col, encoder in encoders.items()]\n",
    "        edge_attr = torch.cat(edge_attrs, dim=-1)\n",
    "\n",
    "    return edge_index, edge_attr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T11:50:27.041355400Z",
     "start_time": "2023-10-19T11:50:26.619486500Z"
    }
   },
   "id": "c4859dd21eecc362"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def tags_encoder(tags):\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    tags_mlb = mlb.fit_transform(tags)\n",
    "    return torch.Tensor(list(tags_mlb))\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class SequenceEncoder:\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2', device=None):\n",
    "        self.device = device\n",
    "        self.model = SentenceTransformer(model_name, device=device)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def __call__(self, df):\n",
    "        x = self.model.encode(df.values, show_progress_bar=True,\n",
    "                              convert_to_tensor=True, device=self.device)\n",
    "        return x.cpu()\n",
    "    \n",
    "class WeekdayEncoder:\n",
    "    def __init__(self, sep='|'):\n",
    "        self.sep = sep\n",
    "\n",
    "    def __call__(self, df):\n",
    "        genres = set(col for col in df.values)\n",
    "        mapping = {genre: i for i, genre in enumerate(genres)}\n",
    "\n",
    "        x = torch.zeros(len(df), len(mapping))\n",
    "        for i, col in enumerate(df.values):\n",
    "            for genre in col.split(self.sep):\n",
    "                x[i, mapping[genre]] = 1\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T11:50:32.874584Z",
     "start_time": "2023-10-19T11:50:26.666355500Z"
    }
   },
   "id": "5f2d78ebb62a77eb"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eirik\\AppData\\Local\\Temp\\ipykernel_5568\\713585520.py:14: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  \"embedding\": lambda x: torch.Tensor(x)\n",
      "C:\\Users\\Eirik\\AppData\\Local\\Temp\\ipykernel_5568\\1332433953.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  return torch.Tensor(list(tags_mlb))\n"
     ]
    }
   ],
   "source": [
    "recipe_query = \"\"\"\n",
    "MATCH (a:Recipe)\n",
    "OPTIONAL MATCH (a)-[:HAS_TAG]->(tag:Tag)\n",
    "RETURN a.recipieId as recipeId,\n",
    "       a.openaiEmbeddings as embedding,\n",
    "       collect(tag.title) AS tags\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "recipe_x, recipe_mapping, recipe_y = load_node(\n",
    "    recipe_query, \n",
    "    index_col='recipeId', \n",
    "    encoders={\n",
    "        \"embedding\": lambda x: torch.Tensor(x)\n",
    "    },\n",
    "    target_encoders={\n",
    "        \"tags\": tags_encoder\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T11:50:38.277167300Z",
     "start_time": "2023-10-19T11:50:32.890206600Z"
    }
   },
   "id": "e9e1f14a0cc1da20"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([723, 1536]), 723, torch.Size([723, 262]))"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_x.shape, len(recipe_mapping), recipe_y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T11:50:38.339665300Z",
     "start_time": "2023-10-19T11:50:38.261550500Z"
    }
   },
   "id": "7a8f888fdda9137f"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/57 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "56ff912acc7b4dcbbe918c6b10e4a5b6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ingredient_query = \"\"\"\n",
    "MATCH (i:Ingredient)\n",
    "RETURN ID(i) as ingredientId, i.title as title\n",
    "\"\"\"\n",
    "ingredient_x, ingredient_mapping, y = load_node(\n",
    "    ingredient_query, \n",
    "    index_col='ingredientId', \n",
    "    encoders={\n",
    "        'title': SequenceEncoder()\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T11:50:47.274906Z",
     "start_time": "2023-10-19T11:50:38.324045Z"
    }
   },
   "id": "d6fdcf042951fc0"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([1793, 384]), 1793)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredient_x.shape, len(ingredient_mapping)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T11:50:47.308285Z",
     "start_time": "2023-10-19T11:50:47.279909200Z"
    }
   },
   "id": "6dd3de1c20740129"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "menu_query = \"\"\"\n",
    "MATCH (m:Menu)\n",
    "RETURN ID(m) as menuId, m.year as year, m.week as week\n",
    "\"\"\"\n",
    "menu_x, menu_mapping, y = load_node(\n",
    "    menu_query, \n",
    "    index_col='menuId',\n",
    "    encoders={\n",
    "        \"year\": lambda x: torch.Tensor(x.tolist()).view(-1, 1),\n",
    "        \"week\": lambda x: torch.Tensor(x.tolist()).view(-1, 1),\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T11:50:47.484635900Z",
     "start_time": "2023-10-19T11:50:47.298915700Z"
    }
   },
   "id": "101ad49116b3994f"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([142, 2]), 142)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "menu_x.shape, len(menu_mapping)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T11:50:47.500808500Z",
     "start_time": "2023-10-19T11:50:47.484635900Z"
    }
   },
   "id": "40da01b9dfcfad8d"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "recipe_menu_query = \"\"\"\n",
    "MATCH (n:Recipe)-[r:IS_PART_OF_MENU]->(m:Menu) \n",
    "RETURN n.recipieId AS recipeId, ID(m) AS menuId, r.weekDay AS weekDay\n",
    "\"\"\"\n",
    "\n",
    "recipe_menu_edge_index, recipe_menu_edge_label = load_edge(\n",
    "    recipe_menu_query,\n",
    "    src_index_col='recipeId',\n",
    "    src_mapping=recipe_mapping,\n",
    "    dst_index_col='menuId',\n",
    "    dst_mapping=menu_mapping,\n",
    "    encoders={'weekDay': WeekdayEncoder()},\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T11:50:47.795151Z",
     "start_time": "2023-10-19T11:50:47.500808500Z"
    }
   },
   "id": "5b201cdc7df4b23f"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([2, 993]), torch.Size([993, 7]))"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_menu_edge_index.shape, recipe_menu_edge_label.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T11:50:47.818338900Z",
     "start_time": "2023-10-19T11:50:47.800164900Z"
    }
   },
   "id": "b3a76f187ca70691"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "recipe_ingredient_query = \"\"\"\n",
    "MATCH (n:Recipe)-[r:HAS_INGREDIENT]->(i:Ingredient) \n",
    "RETURN n.recipieId AS recipeId, ID(i) AS ingredientId\n",
    "\"\"\"\n",
    "\n",
    "recipe_ingredient_edge_index, recipe_ingredient_edge_label = load_edge(\n",
    "    recipe_ingredient_query,\n",
    "    src_index_col='recipeId',\n",
    "    src_mapping=recipe_mapping,\n",
    "    dst_index_col='ingredientId',\n",
    "    dst_mapping=ingredient_mapping,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T11:50:49.885043900Z",
     "start_time": "2023-10-19T11:50:47.818338900Z"
    }
   },
   "id": "e63569124aef7cec"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([2, 7907]), None)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_ingredient_edge_index.shape, recipe_ingredient_edge_label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T11:50:49.902209Z",
     "start_time": "2023-10-19T11:50:49.885043900Z"
    }
   },
   "id": "7bf086b1809709f5"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "HeteroData(\n  num_relations=2,\n  num_classes=262,\n  num_nodes=2658,\n  recipe={\n    x=[723, 1536],\n    y=[723, 262],\n  },\n  menu={ x=[142, 2] },\n  ingredient={ x=[1793, 384] },\n  (recipe, has_ingredient, ingredient)={ edge_index=[2, 7907] },\n  (recipe, is_part_of_menu, menu)={\n    edge_index=[2, 993],\n    edge_attr=[993, 7],\n  }\n)"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "data = HeteroData()\n",
    "\n",
    "data['recipe'].x = recipe_x\n",
    "data['recipe'].y = recipe_y\n",
    "data[\"menu\"].x = menu_x\n",
    "data[\"ingredient\"].x = ingredient_x\n",
    "data[\"recipe\", \"has_ingredient\", \"ingredient\"].edge_index = recipe_ingredient_edge_index\n",
    "data[\"recipe\", \"is_part_of_menu\", \"menu\"].edge_index = recipe_menu_edge_index\n",
    "data[\"recipe\", \"is_part_of_menu\", \"menu\"].edge_attr = recipe_menu_edge_label\n",
    "data.num_relations = 2\n",
    "data.num_classes = recipe_y.shape[-1]\n",
    "data.num_nodes = len(recipe_mapping) + len(ingredient_mapping) + len(menu_mapping)\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:02:46.015842100Z",
     "start_time": "2023-10-19T12:02:45.973631900Z"
    }
   },
   "id": "7ed42e63f442ae0f"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "HeteroData(\n  num_relations=2,\n  num_classes=262,\n  num_nodes=2658,\n  recipe={\n    x=[723, 1536],\n    y=[723, 262],\n  },\n  menu={ x=[142, 2] },\n  ingredient={ x=[1793, 384] },\n  (recipe, has_ingredient, ingredient)={ edge_index=[2, 7907] },\n  (recipe, is_part_of_menu, menu)={\n    edge_index=[2, 993],\n    edge_attr=[993, 7],\n  },\n  (ingredient, rev_has_ingredient, recipe)={ edge_index=[2, 7907] },\n  (menu, rev_is_part_of_menu, recipe)={\n    edge_index=[2, 993],\n    edge_attr=[993, 7],\n  }\n)"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.transforms import ToUndirected\n",
    "\n",
    "data = ToUndirected()(data)\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:02:47.502180300Z",
     "start_time": "2023-10-19T12:02:47.455308500Z"
    }
   },
   "id": "b92685477f3427aa"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "\n",
    "# 2. Perform a link-level split into training, validation, and test edges.\n",
    "transform = RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    neg_sampling_ratio=0.0,\n",
    "    edge_types=[(\"recipe\", \"is_part_of_menu\", \"menu\"), (\"recipe\", \"has_ingredient\", \"ingredient\")],\n",
    "    # rev_edge_types=[('movie', 'rev_rates', 'user')],\n",
    ")\n",
    "train_data, val_data, test_data = transform(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:02:51.189558800Z",
     "start_time": "2023-10-19T12:02:51.158312Z"
    }
   },
   "id": "40fbc3b48bf3660d"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "HeteroData(\n  num_relations=2,\n  num_classes=262,\n  num_nodes=2658,\n  recipe={\n    x=[723, 1536],\n    y=[723, 262],\n  },\n  menu={ x=[142, 2] },\n  ingredient={ x=[1793, 384] },\n  (recipe, has_ingredient, ingredient)={\n    edge_index=[2, 6327],\n    edge_label=[6327],\n    edge_label_index=[2, 6327],\n  },\n  (recipe, is_part_of_menu, menu)={\n    edge_index=[2, 795],\n    edge_attr=[795, 7],\n    edge_label=[795],\n    edge_label_index=[2, 795],\n  },\n  (ingredient, rev_has_ingredient, recipe)={ edge_index=[2, 7907] },\n  (menu, rev_is_part_of_menu, recipe)={\n    edge_index=[2, 993],\n    edge_attr=[993, 7],\n  }\n)"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.metadata()[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:02:53.476851100Z",
     "start_time": "2023-10-19T12:02:53.461224400Z"
    }
   },
   "id": "27ca4cc406072ed3"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv, Linear, to_hetero\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv((-1, -1), hidden_channels, add_self_loops=False)\n",
    "        self.lin1 = Linear(-1, hidden_channels)\n",
    "        self.conv2 = GATConv((-1, -1), out_channels, add_self_loops=False)\n",
    "        self.lin2 = Linear(-1, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index) + self.lin1(x)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index) + self.lin2(x)\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T11:50:50.147179400Z",
     "start_time": "2023-10-19T11:50:50.062996100Z"
    }
   },
   "id": "3aa6fd54bef8a3ef"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "model = GAT(hidden_channels=64, out_channels=data.num_classes)\n",
    "model = to_hetero(model, data.metadata(), aggr='sum')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data, model = data.to(device), model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:03:01.700699200Z",
     "start_time": "2023-10-19T12:03:01.528381600Z"
    }
   },
   "id": "4882d5703529724"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "with torch.no_grad():  # Initialize lazy modules.\n",
    "    out = model(data.x_dict, data.edge_index_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:03:09.931743300Z",
     "start_time": "2023-10-19T12:03:09.851754900Z"
    }
   },
   "id": "5156a1b9be873093"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "98c5a05629c8afc5"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x_dict, data.edge_index_dict)\n",
    "    # mask = data['paper'].train_mask\n",
    "    loss = F.cross_entropy(out['recipe'], data['recipe'].y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a990a1453d55dbd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.324755311012268\n",
      "Validation Loss: 21.23717498779297\n",
      "Epoch 2, Loss: 21.23717498779297\n",
      "Validation Loss: 3.708242893218994\n",
      "Epoch 3, Loss: 3.708242893218994\n",
      "Validation Loss: 2.041651964187622\n",
      "Epoch 4, Loss: 2.041651964187622\n",
      "Validation Loss: 3.559126377105713\n",
      "Epoch 5, Loss: 3.559126377105713\n",
      "Validation Loss: 3.771883964538574\n",
      "Epoch 6, Loss: 3.771883964538574\n",
      "Validation Loss: 3.9242632389068604\n",
      "Epoch 7, Loss: 3.9242632389068604\n",
      "Validation Loss: 4.753610134124756\n",
      "Epoch 8, Loss: 4.753610134124756\n",
      "Validation Loss: 4.958366394042969\n",
      "Epoch 9, Loss: 4.958366394042969\n",
      "Validation Loss: 4.9136962890625\n",
      "Epoch 10, Loss: 4.9136962890625\n",
      "Validation Loss: 5.23234748840332\n",
      "Epoch 11, Loss: 5.23234748840332\n",
      "Validation Loss: 5.568265914916992\n",
      "Epoch 12, Loss: 5.568265914916992\n",
      "Validation Loss: 5.590836048126221\n",
      "Epoch 13, Loss: 5.590836048126221\n",
      "Validation Loss: 5.611876010894775\n",
      "Epoch 14, Loss: 5.611876010894775\n",
      "Validation Loss: 5.548414707183838\n",
      "Epoch 15, Loss: 5.548414707183838\n",
      "Validation Loss: 5.507023334503174\n",
      "Epoch 16, Loss: 5.507023334503174\n",
      "Validation Loss: 5.403979778289795\n",
      "Epoch 17, Loss: 5.403979778289795\n",
      "Validation Loss: 5.289410591125488\n",
      "Epoch 18, Loss: 5.289410591125488\n",
      "Validation Loss: 5.157619476318359\n",
      "Epoch 19, Loss: 5.157619476318359\n",
      "Validation Loss: 5.043684482574463\n",
      "Epoch 20, Loss: 5.043684482574463\n",
      "Validation Loss: 4.8308000564575195\n",
      "Epoch 21, Loss: 4.8308000564575195\n",
      "Validation Loss: 4.619131088256836\n",
      "Epoch 22, Loss: 4.619131088256836\n",
      "Validation Loss: 4.612508773803711\n",
      "Epoch 23, Loss: 4.612508773803711\n",
      "Validation Loss: 4.401632308959961\n",
      "Epoch 24, Loss: 4.401632308959961\n",
      "Validation Loss: 4.225689888000488\n",
      "Epoch 25, Loss: 4.225689888000488\n",
      "Validation Loss: 4.059322357177734\n",
      "Epoch 26, Loss: 4.059322357177734\n",
      "Validation Loss: 4.275806903839111\n",
      "Epoch 27, Loss: 4.275806903839111\n",
      "Validation Loss: 3.853628635406494\n",
      "Epoch 28, Loss: 3.853628635406494\n",
      "Validation Loss: 3.759648323059082\n",
      "Epoch 29, Loss: 3.759648323059082\n",
      "Validation Loss: 3.6567676067352295\n",
      "Epoch 30, Loss: 3.6567676067352295\n",
      "Validation Loss: 3.607152223587036\n",
      "Epoch 31, Loss: 3.607152223587036\n",
      "Validation Loss: 3.396881341934204\n",
      "Epoch 32, Loss: 3.396881341934204\n",
      "Validation Loss: 3.2035253047943115\n",
      "Epoch 33, Loss: 3.2035253047943115\n",
      "Validation Loss: 3.113210439682007\n",
      "Epoch 34, Loss: 3.113210439682007\n",
      "Validation Loss: 2.916137218475342\n",
      "Epoch 35, Loss: 2.916137218475342\n",
      "Validation Loss: 2.6351025104522705\n",
      "Epoch 36, Loss: 2.6351025104522705\n",
      "Validation Loss: 2.814795970916748\n",
      "Epoch 37, Loss: 2.814795970916748\n",
      "Validation Loss: 2.4619319438934326\n",
      "Epoch 38, Loss: 2.4619319438934326\n",
      "Validation Loss: 2.4401018619537354\n",
      "Epoch 39, Loss: 2.4401018619537354\n",
      "Validation Loss: 2.406078338623047\n",
      "Epoch 40, Loss: 2.406078338623047\n",
      "Validation Loss: 2.428054094314575\n",
      "Epoch 41, Loss: 2.428054094314575\n",
      "Validation Loss: 2.354213237762451\n",
      "Epoch 42, Loss: 2.354213237762451\n",
      "Validation Loss: 2.313800573348999\n",
      "Epoch 43, Loss: 2.313800573348999\n",
      "Validation Loss: 2.3287692070007324\n",
      "Epoch 44, Loss: 2.3287692070007324\n",
      "Validation Loss: 2.2453014850616455\n",
      "Epoch 45, Loss: 2.2453014850616455\n",
      "Validation Loss: 2.1026759147644043\n",
      "Epoch 46, Loss: 2.1026759147644043\n",
      "Validation Loss: 2.4126830101013184\n",
      "Epoch 47, Loss: 2.4126830101013184\n",
      "Validation Loss: 2.062535047531128\n",
      "Epoch 48, Loss: 2.062535047531128\n",
      "Validation Loss: 1.9629672765731812\n",
      "Epoch 49, Loss: 1.9629672765731812\n",
      "Validation Loss: 2.043757200241089\n",
      "Epoch 50, Loss: 2.043757200241089\n",
      "Validation Loss: 1.9228355884552002\n",
      "Epoch 51, Loss: 1.9228355884552002\n",
      "Validation Loss: 1.889420509338379\n",
      "Epoch 52, Loss: 1.889420509338379\n",
      "Validation Loss: 1.9342899322509766\n",
      "Epoch 53, Loss: 1.9342899322509766\n",
      "Validation Loss: 1.8052617311477661\n",
      "Epoch 54, Loss: 1.8052617311477661\n",
      "Validation Loss: 1.7714674472808838\n",
      "Epoch 55, Loss: 1.7714674472808838\n",
      "Validation Loss: 1.8116121292114258\n",
      "Epoch 56, Loss: 1.8116121292114258\n",
      "Validation Loss: 1.7707927227020264\n",
      "Epoch 57, Loss: 1.7707927227020264\n",
      "Validation Loss: 1.9192545413970947\n",
      "Epoch 58, Loss: 1.9192545413970947\n",
      "Validation Loss: 1.7524769306182861\n",
      "Epoch 59, Loss: 1.7524769306182861\n",
      "Validation Loss: 1.813813328742981\n",
      "Epoch 60, Loss: 1.813813328742981\n",
      "Validation Loss: 1.887988567352295\n",
      "Epoch 61, Loss: 1.887988567352295\n",
      "Validation Loss: 1.7923524379730225\n",
      "Epoch 62, Loss: 1.7923524379730225\n",
      "Validation Loss: 1.8815497159957886\n",
      "Epoch 63, Loss: 1.8815497159957886\n",
      "Validation Loss: 1.8194118738174438\n",
      "Epoch 64, Loss: 1.8194118738174438\n",
      "Validation Loss: 1.8127751350402832\n",
      "Epoch 65, Loss: 1.8127751350402832\n",
      "Validation Loss: 1.7836436033248901\n",
      "Epoch 66, Loss: 1.7836436033248901\n",
      "Validation Loss: 1.788635015487671\n",
      "Epoch 67, Loss: 1.788635015487671\n",
      "Validation Loss: 1.7573124170303345\n",
      "Epoch 68, Loss: 1.7573124170303345\n",
      "Validation Loss: 1.7623169422149658\n",
      "Epoch 69, Loss: 1.7623169422149658\n",
      "Validation Loss: 1.7751812934875488\n",
      "Epoch 70, Loss: 1.7751812934875488\n",
      "Validation Loss: 1.7544491291046143\n",
      "Epoch 71, Loss: 1.7544491291046143\n",
      "Validation Loss: 1.7728731632232666\n",
      "Epoch 72, Loss: 1.7728731632232666\n",
      "Validation Loss: 1.7117842435836792\n",
      "Epoch 73, Loss: 1.7117842435836792\n",
      "Validation Loss: 1.727564811706543\n",
      "Epoch 74, Loss: 1.727564811706543\n",
      "Validation Loss: 1.711006760597229\n",
      "Epoch 75, Loss: 1.711006760597229\n",
      "Validation Loss: 1.697422742843628\n",
      "Epoch 76, Loss: 1.697422742843628\n",
      "Validation Loss: 1.619585633277893\n",
      "Epoch 77, Loss: 1.619585633277893\n",
      "Validation Loss: 1.563693881034851\n",
      "Epoch 78, Loss: 1.563693881034851\n",
      "Validation Loss: 1.5980517864227295\n",
      "Epoch 79, Loss: 1.5980517864227295\n",
      "Validation Loss: 1.4979462623596191\n",
      "Epoch 80, Loss: 1.4979462623596191\n",
      "Validation Loss: 1.5550086498260498\n",
      "Epoch 81, Loss: 1.5550086498260498\n",
      "Validation Loss: 1.5589873790740967\n",
      "Epoch 82, Loss: 1.5589873790740967\n",
      "Validation Loss: 1.5158472061157227\n",
      "Epoch 83, Loss: 1.5158472061157227\n",
      "Validation Loss: 1.4844200611114502\n",
      "Epoch 84, Loss: 1.4844200611114502\n",
      "Validation Loss: 1.5666464567184448\n",
      "Epoch 85, Loss: 1.5666464567184448\n",
      "Validation Loss: 1.473274827003479\n",
      "Epoch 86, Loss: 1.473274827003479\n",
      "Validation Loss: 1.5622739791870117\n",
      "Epoch 87, Loss: 1.5622739791870117\n",
      "Validation Loss: 1.5290141105651855\n",
      "Epoch 88, Loss: 1.5290141105651855\n",
      "Validation Loss: 1.4836387634277344\n",
      "Epoch 89, Loss: 1.4836387634277344\n",
      "Validation Loss: 1.4401493072509766\n",
      "Epoch 90, Loss: 1.4401493072509766\n",
      "Validation Loss: 1.4680531024932861\n",
      "Epoch 91, Loss: 1.4680531024932861\n",
      "Validation Loss: 1.4746546745300293\n",
      "Epoch 92, Loss: 1.4746546745300293\n",
      "Validation Loss: 1.4020899534225464\n",
      "Epoch 93, Loss: 1.4020899534225464\n",
      "Validation Loss: 1.4726126194000244\n",
      "Epoch 94, Loss: 1.4726126194000244\n",
      "Validation Loss: 1.449162244796753\n",
      "Epoch 95, Loss: 1.449162244796753\n",
      "Validation Loss: 1.4551985263824463\n",
      "Epoch 96, Loss: 1.4551985263824463\n",
      "Validation Loss: 1.50523042678833\n",
      "Epoch 97, Loss: 1.50523042678833\n",
      "Validation Loss: 1.4084984064102173\n",
      "Epoch 98, Loss: 1.4084984064102173\n",
      "Validation Loss: 1.3745568990707397\n",
      "Epoch 99, Loss: 1.3745568990707397\n",
      "Validation Loss: 1.3784306049346924\n",
      "Epoch 100, Loss: 1.3784306049346924\n",
      "Validation Loss: 1.3317888975143433\n",
      "Epoch 101, Loss: 1.3317888975143433\n",
      "Validation Loss: 1.3269121646881104\n",
      "Epoch 102, Loss: 1.3269121646881104\n",
      "Validation Loss: 1.4099209308624268\n",
      "Epoch 103, Loss: 1.4099209308624268\n",
      "Validation Loss: 1.3117345571517944\n",
      "Epoch 104, Loss: 1.3117345571517944\n",
      "Validation Loss: 1.3117772340774536\n",
      "Epoch 105, Loss: 1.3117772340774536\n",
      "Validation Loss: 1.3160721063613892\n",
      "Epoch 106, Loss: 1.3160721063613892\n",
      "Validation Loss: 1.3282033205032349\n",
      "Epoch 107, Loss: 1.3282033205032349\n",
      "Validation Loss: 1.2716010808944702\n",
      "Epoch 108, Loss: 1.2716010808944702\n",
      "Validation Loss: 1.242794394493103\n",
      "Epoch 109, Loss: 1.242794394493103\n",
      "Validation Loss: 1.2906163930892944\n",
      "Epoch 110, Loss: 1.2906163930892944\n",
      "Validation Loss: 1.2116166353225708\n",
      "Epoch 111, Loss: 1.2116166353225708\n",
      "Validation Loss: 1.256456732749939\n",
      "Epoch 112, Loss: 1.256456732749939\n",
      "Validation Loss: 1.2269593477249146\n",
      "Epoch 113, Loss: 1.2269593477249146\n",
      "Validation Loss: 1.3151772022247314\n",
      "Epoch 114, Loss: 1.3151772022247314\n",
      "Validation Loss: 1.308421015739441\n",
      "Epoch 115, Loss: 1.308421015739441\n",
      "Validation Loss: 1.338716983795166\n",
      "Epoch 116, Loss: 1.338716983795166\n",
      "Validation Loss: 1.3632988929748535\n",
      "Epoch 117, Loss: 1.3632988929748535\n",
      "Validation Loss: 1.3064770698547363\n",
      "Epoch 118, Loss: 1.3064770698547363\n",
      "Validation Loss: 1.366446614265442\n",
      "Epoch 119, Loss: 1.366446614265442\n",
      "Validation Loss: 1.309427261352539\n",
      "Epoch 120, Loss: 1.309427261352539\n",
      "Validation Loss: 1.3144149780273438\n",
      "Epoch 121, Loss: 1.3144149780273438\n",
      "Validation Loss: 1.2906564474105835\n",
      "Epoch 122, Loss: 1.2906564474105835\n",
      "Validation Loss: 1.3100335597991943\n",
      "Epoch 123, Loss: 1.3100335597991943\n",
      "Validation Loss: 1.3332183361053467\n",
      "Epoch 124, Loss: 1.3332183361053467\n",
      "Validation Loss: 1.351089596748352\n",
      "Epoch 125, Loss: 1.351089596748352\n",
      "Validation Loss: 1.3711433410644531\n",
      "Epoch 126, Loss: 1.3711433410644531\n",
      "Validation Loss: 1.3018865585327148\n",
      "Epoch 127, Loss: 1.3018865585327148\n",
      "Validation Loss: 1.339465618133545\n",
      "Epoch 128, Loss: 1.339465618133545\n",
      "Validation Loss: 1.2775768041610718\n",
      "Epoch 129, Loss: 1.2775768041610718\n",
      "Validation Loss: 1.2937581539154053\n",
      "Epoch 130, Loss: 1.2937581539154053\n",
      "Validation Loss: 1.2279844284057617\n",
      "Epoch 131, Loss: 1.2279844284057617\n",
      "Validation Loss: 1.2747622728347778\n",
      "Epoch 132, Loss: 1.2747622728347778\n",
      "Validation Loss: 1.3254996538162231\n",
      "Epoch 133, Loss: 1.3254996538162231\n",
      "Validation Loss: 1.3214902877807617\n",
      "Epoch 134, Loss: 1.3214902877807617\n",
      "Validation Loss: 1.3448686599731445\n",
      "Epoch 135, Loss: 1.3448686599731445\n",
      "Validation Loss: 1.2640074491500854\n",
      "Epoch 136, Loss: 1.2640074491500854\n",
      "Validation Loss: 1.2624058723449707\n",
      "Epoch 137, Loss: 1.2624058723449707\n",
      "Validation Loss: 1.3072278499603271\n",
      "Epoch 138, Loss: 1.3072278499603271\n",
      "Validation Loss: 1.2475862503051758\n",
      "Epoch 139, Loss: 1.2475862503051758\n",
      "Validation Loss: 1.2387111186981201\n",
      "Epoch 140, Loss: 1.2387111186981201\n",
      "Validation Loss: 1.2610304355621338\n",
      "Epoch 141, Loss: 1.2610304355621338\n",
      "Validation Loss: 1.2318099737167358\n",
      "Epoch 142, Loss: 1.2318099737167358\n",
      "Validation Loss: 1.2580779790878296\n",
      "Epoch 143, Loss: 1.2580779790878296\n",
      "Validation Loss: 1.2474267482757568\n",
      "Epoch 144, Loss: 1.2474267482757568\n",
      "Validation Loss: 1.331078290939331\n",
      "Epoch 145, Loss: 1.331078290939331\n",
      "Validation Loss: 1.3115980625152588\n",
      "Epoch 146, Loss: 1.3115980625152588\n",
      "Validation Loss: 1.3718551397323608\n",
      "Epoch 147, Loss: 1.3718551397323608\n",
      "Validation Loss: 1.400020956993103\n",
      "Epoch 148, Loss: 1.400020956993103\n",
      "Validation Loss: 1.3557268381118774\n",
      "Epoch 149, Loss: 1.3557268381118774\n",
      "Validation Loss: 1.3150177001953125\n",
      "Epoch 150, Loss: 1.3150177001953125\n",
      "Validation Loss: 1.25077223777771\n",
      "Epoch 151, Loss: 1.25077223777771\n",
      "Validation Loss: 1.2345231771469116\n",
      "Epoch 152, Loss: 1.2345231771469116\n",
      "Validation Loss: 1.2286112308502197\n",
      "Epoch 153, Loss: 1.2286112308502197\n",
      "Validation Loss: 1.1666812896728516\n",
      "Epoch 154, Loss: 1.1666812896728516\n",
      "Validation Loss: 1.1824241876602173\n",
      "Epoch 155, Loss: 1.1824241876602173\n",
      "Validation Loss: 1.23885977268219\n",
      "Epoch 156, Loss: 1.23885977268219\n",
      "Validation Loss: 1.2013927698135376\n",
      "Epoch 157, Loss: 1.2013927698135376\n",
      "Validation Loss: 1.2598401308059692\n",
      "Epoch 158, Loss: 1.2598401308059692\n",
      "Validation Loss: 1.309627890586853\n",
      "Epoch 159, Loss: 1.309627890586853\n",
      "Validation Loss: 1.2604739665985107\n",
      "Epoch 160, Loss: 1.2604739665985107\n",
      "Validation Loss: 1.296072244644165\n",
      "Epoch 161, Loss: 1.296072244644165\n",
      "Validation Loss: 1.2559642791748047\n",
      "Epoch 162, Loss: 1.2559642791748047\n",
      "Validation Loss: 1.2657802104949951\n",
      "Epoch 163, Loss: 1.2657802104949951\n",
      "Validation Loss: 1.2258093357086182\n",
      "Epoch 164, Loss: 1.2258093357086182\n",
      "Validation Loss: 1.2882802486419678\n",
      "Epoch 165, Loss: 1.2882802486419678\n",
      "Validation Loss: 1.2815107107162476\n",
      "Epoch 166, Loss: 1.2815107107162476\n",
      "Validation Loss: 1.2450240850448608\n",
      "Epoch 167, Loss: 1.2450240850448608\n",
      "Validation Loss: 1.2892577648162842\n",
      "Epoch 168, Loss: 1.2892577648162842\n",
      "Validation Loss: 1.2252732515335083\n",
      "Epoch 169, Loss: 1.2252732515335083\n",
      "Validation Loss: 1.2039427757263184\n",
      "Epoch 170, Loss: 1.2039427757263184\n",
      "Validation Loss: 1.2526402473449707\n",
      "Epoch 171, Loss: 1.2526402473449707\n",
      "Validation Loss: 1.246057391166687\n",
      "Epoch 172, Loss: 1.246057391166687\n",
      "Validation Loss: 1.192063331604004\n",
      "Epoch 173, Loss: 1.192063331604004\n",
      "Validation Loss: 1.2267732620239258\n",
      "Epoch 174, Loss: 1.2267732620239258\n",
      "Validation Loss: 1.1752923727035522\n",
      "Epoch 175, Loss: 1.1752923727035522\n",
      "Validation Loss: 1.1749892234802246\n",
      "Epoch 176, Loss: 1.1749892234802246\n",
      "Validation Loss: 1.2590274810791016\n",
      "Epoch 177, Loss: 1.2590274810791016\n",
      "Validation Loss: 1.1269584894180298\n",
      "Epoch 178, Loss: 1.1269584894180298\n",
      "Validation Loss: 1.1370582580566406\n",
      "Epoch 179, Loss: 1.1370582580566406\n",
      "Validation Loss: 1.121041178703308\n",
      "Epoch 180, Loss: 1.121041178703308\n",
      "Validation Loss: 1.1340619325637817\n",
      "Epoch 181, Loss: 1.1340619325637817\n",
      "Validation Loss: 1.1471763849258423\n",
      "Epoch 182, Loss: 1.1471763849258423\n",
      "Validation Loss: 1.122548222541809\n",
      "Epoch 183, Loss: 1.122548222541809\n",
      "Validation Loss: 1.134221076965332\n",
      "Epoch 184, Loss: 1.134221076965332\n",
      "Validation Loss: 1.0959454774856567\n",
      "Epoch 185, Loss: 1.0959454774856567\n",
      "Validation Loss: 1.105707049369812\n",
      "Epoch 186, Loss: 1.105707049369812\n",
      "Validation Loss: 1.0959678888320923\n",
      "Epoch 187, Loss: 1.0959678888320923\n",
      "Validation Loss: 1.0458742380142212\n",
      "Epoch 188, Loss: 1.0458742380142212\n",
      "Validation Loss: 1.043304681777954\n",
      "Epoch 189, Loss: 1.043304681777954\n",
      "Validation Loss: 1.0520894527435303\n",
      "Epoch 190, Loss: 1.0520894527435303\n",
      "Validation Loss: 1.0684198141098022\n",
      "Epoch 191, Loss: 1.0684198141098022\n",
      "Validation Loss: 1.1024911403656006\n",
      "Epoch 192, Loss: 1.1024911403656006\n",
      "Validation Loss: 1.1080495119094849\n",
      "Epoch 193, Loss: 1.1080495119094849\n",
      "Validation Loss: 1.0452698469161987\n",
      "Epoch 194, Loss: 1.0452698469161987\n",
      "Validation Loss: 1.0640039443969727\n",
      "Epoch 195, Loss: 1.0640039443969727\n",
      "Validation Loss: 1.037609338760376\n",
      "Epoch 196, Loss: 1.037609338760376\n",
      "Validation Loss: 1.0229653120040894\n",
      "Epoch 197, Loss: 1.0229653120040894\n",
      "Validation Loss: 1.0116316080093384\n",
      "Epoch 198, Loss: 1.0116316080093384\n",
      "Validation Loss: 1.0127379894256592\n",
      "Epoch 199, Loss: 1.0127379894256592\n",
      "Validation Loss: 0.9889870285987854\n",
      "Epoch 200, Loss: 0.9889870285987854\n",
      "Validation Loss: 1.0135668516159058\n",
      "Epoch 201, Loss: 1.0135668516159058\n",
      "Validation Loss: 0.9599807262420654\n",
      "Epoch 202, Loss: 0.9599807262420654\n",
      "Validation Loss: 1.02083420753479\n",
      "Epoch 203, Loss: 1.02083420753479\n",
      "Validation Loss: 0.9832121133804321\n",
      "Epoch 204, Loss: 0.9832121133804321\n",
      "Validation Loss: 0.9729434251785278\n",
      "Epoch 205, Loss: 0.9729434251785278\n",
      "Validation Loss: 1.0571633577346802\n",
      "Epoch 206, Loss: 1.0571633577346802\n",
      "Validation Loss: 0.9896084666252136\n",
      "Epoch 207, Loss: 0.9896084666252136\n",
      "Validation Loss: 1.0332139730453491\n",
      "Epoch 208, Loss: 1.0332139730453491\n",
      "Validation Loss: 0.9861931800842285\n",
      "Epoch 209, Loss: 0.9861931800842285\n",
      "Validation Loss: 1.0352602005004883\n",
      "Epoch 210, Loss: 1.0352602005004883\n",
      "Validation Loss: 1.0021103620529175\n",
      "Epoch 211, Loss: 1.0021103620529175\n",
      "Validation Loss: 1.0118485689163208\n",
      "Epoch 212, Loss: 1.0118485689163208\n",
      "Validation Loss: 0.9912468194961548\n",
      "Epoch 213, Loss: 0.9912468194961548\n",
      "Validation Loss: 1.086257815361023\n",
      "Epoch 214, Loss: 1.086257815361023\n",
      "Validation Loss: 1.0133306980133057\n",
      "Epoch 215, Loss: 1.0133306980133057\n",
      "Validation Loss: 1.0489352941513062\n",
      "Epoch 216, Loss: 1.0489352941513062\n",
      "Validation Loss: 1.0629944801330566\n",
      "Epoch 217, Loss: 1.0629944801330566\n",
      "Validation Loss: 1.0369057655334473\n",
      "Epoch 218, Loss: 1.0369057655334473\n",
      "Validation Loss: 1.0530275106430054\n",
      "Epoch 219, Loss: 1.0530275106430054\n",
      "Validation Loss: 1.007729172706604\n",
      "Epoch 220, Loss: 1.007729172706604\n",
      "Validation Loss: 1.0147525072097778\n",
      "Epoch 221, Loss: 1.0147525072097778\n",
      "Validation Loss: 0.9933935403823853\n",
      "Epoch 222, Loss: 0.9933935403823853\n",
      "Validation Loss: 1.0216925144195557\n",
      "Epoch 223, Loss: 1.0216925144195557\n",
      "Validation Loss: 0.980514645576477\n",
      "Epoch 224, Loss: 0.980514645576477\n",
      "Validation Loss: 0.992307186126709\n",
      "Epoch 225, Loss: 0.992307186126709\n",
      "Validation Loss: 0.9292929768562317\n",
      "Epoch 226, Loss: 0.9292929768562317\n",
      "Validation Loss: 0.9165378212928772\n",
      "Epoch 227, Loss: 0.9165378212928772\n",
      "Validation Loss: 0.8925185203552246\n",
      "Epoch 228, Loss: 0.8925185203552246\n",
      "Validation Loss: 0.8872532844543457\n",
      "Epoch 229, Loss: 0.8872532844543457\n",
      "Validation Loss: 0.868025541305542\n",
      "Epoch 230, Loss: 0.868025541305542\n",
      "Validation Loss: 0.8517709374427795\n",
      "Epoch 231, Loss: 0.8517709374427795\n",
      "Validation Loss: 0.8366455435752869\n",
      "Epoch 232, Loss: 0.8366455435752869\n",
      "Validation Loss: 0.9908203482627869\n",
      "Epoch 233, Loss: 0.9908203482627869\n",
      "Validation Loss: 0.9078986644744873\n",
      "Epoch 234, Loss: 0.9078986644744873\n",
      "Validation Loss: 0.9841585755348206\n",
      "Epoch 235, Loss: 0.9841585755348206\n",
      "Validation Loss: 0.9968836903572083\n",
      "Epoch 236, Loss: 0.9968836903572083\n",
      "Validation Loss: 1.0260305404663086\n",
      "Epoch 237, Loss: 1.0260305404663086\n",
      "Validation Loss: 1.0022774934768677\n",
      "Epoch 238, Loss: 1.0022774934768677\n",
      "Validation Loss: 1.0065314769744873\n",
      "Epoch 239, Loss: 1.0065314769744873\n",
      "Validation Loss: 1.005887746810913\n",
      "Epoch 240, Loss: 1.005887746810913\n",
      "Validation Loss: 0.988956093788147\n",
      "Epoch 241, Loss: 0.988956093788147\n",
      "Validation Loss: 0.9593327045440674\n",
      "Epoch 242, Loss: 0.9593327045440674\n",
      "Validation Loss: 0.9587077498435974\n",
      "Epoch 243, Loss: 0.9587077498435974\n",
      "Validation Loss: 0.9607595801353455\n",
      "Epoch 244, Loss: 0.9607595801353455\n",
      "Validation Loss: 0.9387663006782532\n",
      "Epoch 245, Loss: 0.9387663006782532\n",
      "Validation Loss: 0.9586977362632751\n",
      "Epoch 246, Loss: 0.9586977362632751\n",
      "Validation Loss: 0.9651761054992676\n",
      "Epoch 247, Loss: 0.9651761054992676\n",
      "Validation Loss: 0.9209145903587341\n",
      "Epoch 248, Loss: 0.9209145903587341\n",
      "Validation Loss: 0.9577457904815674\n",
      "Epoch 249, Loss: 0.9577457904815674\n",
      "Validation Loss: 0.908459484577179\n",
      "Epoch 250, Loss: 0.908459484577179\n",
      "Validation Loss: 0.9041401743888855\n",
      "Epoch 251, Loss: 0.9041401743888855\n",
      "Validation Loss: 0.9046447277069092\n",
      "Epoch 252, Loss: 0.9046447277069092\n",
      "Validation Loss: 0.8665531277656555\n",
      "Epoch 253, Loss: 0.8665531277656555\n",
      "Validation Loss: 0.8979707360267639\n",
      "Epoch 254, Loss: 0.8979707360267639\n",
      "Validation Loss: 0.9095519185066223\n",
      "Epoch 255, Loss: 0.9095519185066223\n",
      "Validation Loss: 0.919927179813385\n",
      "Epoch 256, Loss: 0.919927179813385\n",
      "Validation Loss: 0.9221171140670776\n",
      "Epoch 257, Loss: 0.9221171140670776\n",
      "Validation Loss: 0.9478713274002075\n",
      "Epoch 258, Loss: 0.9478713274002075\n",
      "Validation Loss: 0.9620118737220764\n",
      "Epoch 259, Loss: 0.9620118737220764\n",
      "Validation Loss: 0.9566072225570679\n",
      "Epoch 260, Loss: 0.9566072225570679\n",
      "Validation Loss: 0.9172850847244263\n",
      "Epoch 261, Loss: 0.9172850847244263\n",
      "Validation Loss: 0.9458305835723877\n",
      "Epoch 262, Loss: 0.9458305835723877\n",
      "Validation Loss: 0.8802210092544556\n",
      "Epoch 263, Loss: 0.8802210092544556\n",
      "Validation Loss: 0.900981605052948\n",
      "Epoch 264, Loss: 0.900981605052948\n",
      "Validation Loss: 0.8861672878265381\n",
      "Epoch 265, Loss: 0.8861672878265381\n",
      "Validation Loss: 0.9031735062599182\n",
      "Epoch 266, Loss: 0.9031735062599182\n",
      "Validation Loss: 0.9207424521446228\n",
      "Epoch 267, Loss: 0.9207424521446228\n",
      "Validation Loss: 0.8695911169052124\n",
      "Epoch 268, Loss: 0.8695911169052124\n",
      "Validation Loss: 0.894250750541687\n",
      "Epoch 269, Loss: 0.894250750541687\n",
      "Validation Loss: 0.8369646072387695\n",
      "Epoch 270, Loss: 0.8369646072387695\n",
      "Validation Loss: 0.8440222144126892\n",
      "Epoch 271, Loss: 0.8440222144126892\n",
      "Validation Loss: 0.8277081847190857\n",
      "Epoch 272, Loss: 0.8277081847190857\n",
      "Validation Loss: 0.8551523685455322\n",
      "Epoch 273, Loss: 0.8551523685455322\n",
      "Validation Loss: 0.8436199426651001\n",
      "Epoch 274, Loss: 0.8436199426651001\n",
      "Validation Loss: 0.8289939165115356\n",
      "Epoch 275, Loss: 0.8289939165115356\n",
      "Validation Loss: 0.8193458318710327\n",
      "Epoch 276, Loss: 0.8193458318710327\n",
      "Validation Loss: 0.8281931281089783\n",
      "Epoch 277, Loss: 0.8281931281089783\n",
      "Validation Loss: 0.8405636548995972\n",
      "Epoch 278, Loss: 0.8405636548995972\n",
      "Validation Loss: 0.8147414922714233\n",
      "Epoch 279, Loss: 0.8147414922714233\n",
      "Validation Loss: 0.7987613081932068\n",
      "Epoch 280, Loss: 0.7987613081932068\n",
      "Validation Loss: 0.7746714353561401\n",
      "Epoch 281, Loss: 0.7746714353561401\n",
      "Validation Loss: 0.7889797687530518\n",
      "Epoch 282, Loss: 0.7889797687530518\n",
      "Validation Loss: 0.7802254557609558\n",
      "Epoch 283, Loss: 0.7802254557609558\n",
      "Validation Loss: 0.8257117867469788\n",
      "Epoch 284, Loss: 0.8257117867469788\n",
      "Validation Loss: 0.8282757997512817\n",
      "Epoch 285, Loss: 0.8282757997512817\n",
      "Validation Loss: 0.8305756449699402\n",
      "Epoch 286, Loss: 0.8305756449699402\n",
      "Validation Loss: 0.8116375803947449\n",
      "Epoch 287, Loss: 0.8116375803947449\n",
      "Validation Loss: 0.7999001145362854\n",
      "Epoch 288, Loss: 0.7999001145362854\n",
      "Validation Loss: 0.7391898036003113\n",
      "Epoch 289, Loss: 0.7391898036003113\n",
      "Validation Loss: 0.7954931855201721\n",
      "Epoch 290, Loss: 0.7954931855201721\n",
      "Validation Loss: 0.725276529788971\n",
      "Epoch 291, Loss: 0.725276529788971\n",
      "Validation Loss: 0.7280423641204834\n",
      "Epoch 292, Loss: 0.7280423641204834\n",
      "Validation Loss: 0.7965821027755737\n",
      "Epoch 293, Loss: 0.7965821027755737\n",
      "Validation Loss: 0.756129264831543\n",
      "Epoch 294, Loss: 0.756129264831543\n",
      "Validation Loss: 0.7913065552711487\n",
      "Epoch 295, Loss: 0.7913065552711487\n",
      "Validation Loss: 0.7946214079856873\n",
      "Epoch 296, Loss: 0.7946214079856873\n",
      "Validation Loss: 0.7813777923583984\n",
      "Epoch 297, Loss: 0.7813777923583984\n",
      "Validation Loss: 0.7748197913169861\n",
      "Epoch 298, Loss: 0.7748197913169861\n",
      "Validation Loss: 0.7863175868988037\n",
      "Epoch 299, Loss: 0.7863175868988037\n",
      "Validation Loss: 0.7612941265106201\n",
      "Epoch 300, Loss: 0.7612941265106201\n",
      "Validation Loss: 0.7849676609039307\n",
      "Epoch 301, Loss: 0.7849676609039307\n",
      "Validation Loss: 0.7533721923828125\n",
      "Epoch 302, Loss: 0.7533721923828125\n",
      "Validation Loss: 0.7435625195503235\n",
      "Epoch 303, Loss: 0.7435625195503235\n",
      "Validation Loss: 0.772986888885498\n",
      "Epoch 304, Loss: 0.772986888885498\n",
      "Validation Loss: 0.7619406580924988\n",
      "Epoch 305, Loss: 0.7619406580924988\n",
      "Validation Loss: 0.7920332551002502\n",
      "Epoch 306, Loss: 0.7920332551002502\n",
      "Validation Loss: 0.7992246747016907\n",
      "Epoch 307, Loss: 0.7992246747016907\n",
      "Validation Loss: 0.7972128391265869\n",
      "Epoch 308, Loss: 0.7972128391265869\n",
      "Validation Loss: 0.7932479381561279\n",
      "Epoch 309, Loss: 0.7932479381561279\n",
      "Validation Loss: 0.7626937031745911\n",
      "Epoch 310, Loss: 0.7626937031745911\n",
      "Validation Loss: 0.7714561223983765\n",
      "Epoch 311, Loss: 0.7714561223983765\n",
      "Validation Loss: 0.7632687091827393\n",
      "Epoch 312, Loss: 0.7632687091827393\n",
      "Validation Loss: 0.7480137348175049\n",
      "Epoch 313, Loss: 0.7480137348175049\n",
      "Validation Loss: 0.7527086734771729\n",
      "Epoch 314, Loss: 0.7527086734771729\n",
      "Validation Loss: 0.7222673892974854\n",
      "Epoch 315, Loss: 0.7222673892974854\n",
      "Validation Loss: 0.6884304881095886\n",
      "Epoch 316, Loss: 0.6884304881095886\n",
      "Validation Loss: 0.6898107528686523\n",
      "Epoch 317, Loss: 0.6898107528686523\n",
      "Validation Loss: 0.6552854776382446\n",
      "Epoch 318, Loss: 0.6552854776382446\n",
      "Validation Loss: 0.669505774974823\n",
      "Epoch 319, Loss: 0.669505774974823\n",
      "Validation Loss: 0.6396571397781372\n",
      "Epoch 320, Loss: 0.6396571397781372\n",
      "Validation Loss: 0.6569637656211853\n",
      "Epoch 321, Loss: 0.6569637656211853\n",
      "Validation Loss: 0.631928026676178\n",
      "Epoch 322, Loss: 0.631928026676178\n",
      "Validation Loss: 0.6613672971725464\n",
      "Epoch 323, Loss: 0.6613672971725464\n",
      "Validation Loss: 0.6754056215286255\n",
      "Epoch 324, Loss: 0.6754056215286255\n",
      "Validation Loss: 0.7025322318077087\n",
      "Epoch 325, Loss: 0.7025322318077087\n",
      "Validation Loss: 0.6943562626838684\n",
      "Epoch 326, Loss: 0.6943562626838684\n",
      "Validation Loss: 0.7014123201370239\n",
      "Epoch 327, Loss: 0.7014123201370239\n",
      "Validation Loss: 0.6674662232398987\n",
      "Epoch 328, Loss: 0.6674662232398987\n",
      "Validation Loss: 0.7270158529281616\n",
      "Epoch 329, Loss: 0.7270158529281616\n",
      "Validation Loss: 0.7148902416229248\n",
      "Epoch 330, Loss: 0.7148902416229248\n",
      "Validation Loss: 0.7502843141555786\n",
      "Epoch 331, Loss: 0.7502843141555786\n",
      "Validation Loss: 0.7586959004402161\n",
      "Epoch 332, Loss: 0.7586959004402161\n",
      "Validation Loss: 0.7890843749046326\n",
      "Epoch 333, Loss: 0.7890843749046326\n",
      "Validation Loss: 0.7347140312194824\n",
      "Epoch 334, Loss: 0.7347140312194824\n",
      "Validation Loss: 0.762123703956604\n",
      "Epoch 335, Loss: 0.762123703956604\n",
      "Validation Loss: 0.7332468628883362\n",
      "Epoch 336, Loss: 0.7332468628883362\n",
      "Validation Loss: 0.718472957611084\n",
      "Epoch 337, Loss: 0.718472957611084\n",
      "Validation Loss: 0.7356169819831848\n",
      "Epoch 338, Loss: 0.7356169819831848\n",
      "Validation Loss: 0.7199475169181824\n",
      "Epoch 339, Loss: 0.7199475169181824\n",
      "Validation Loss: 0.7250712513923645\n",
      "Epoch 340, Loss: 0.7250712513923645\n",
      "Validation Loss: 0.6857845187187195\n",
      "Epoch 341, Loss: 0.6857845187187195\n",
      "Validation Loss: 0.7042868733406067\n",
      "Epoch 342, Loss: 0.7042868733406067\n",
      "Validation Loss: 0.6983585357666016\n",
      "Epoch 343, Loss: 0.6983585357666016\n",
      "Validation Loss: 0.6929160952568054\n",
      "Epoch 344, Loss: 0.6929160952568054\n",
      "Validation Loss: 0.7103416919708252\n",
      "Epoch 345, Loss: 0.7103416919708252\n",
      "Validation Loss: 0.6979885697364807\n",
      "Epoch 346, Loss: 0.6979885697364807\n",
      "Validation Loss: 0.6916407942771912\n",
      "Epoch 347, Loss: 0.6916407942771912\n",
      "Validation Loss: 0.6959816813468933\n",
      "Epoch 348, Loss: 0.6959816813468933\n",
      "Validation Loss: 0.6709073781967163\n",
      "Epoch 349, Loss: 0.6709073781967163\n",
      "Validation Loss: 0.6526275277137756\n",
      "Epoch 350, Loss: 0.6526275277137756\n",
      "Validation Loss: 0.6588678359985352\n",
      "Epoch 351, Loss: 0.6588678359985352\n",
      "Validation Loss: 0.6506166458129883\n",
      "Epoch 352, Loss: 0.6506166458129883\n",
      "Validation Loss: 0.6520535349845886\n",
      "Epoch 353, Loss: 0.6520535349845886\n",
      "Validation Loss: 0.6438015699386597\n",
      "Epoch 354, Loss: 0.6438015699386597\n",
      "Validation Loss: 0.6487923264503479\n",
      "Epoch 355, Loss: 0.6487923264503479\n",
      "Validation Loss: 0.6476014852523804\n",
      "Epoch 356, Loss: 0.6476014852523804\n",
      "Validation Loss: 0.6758482456207275\n",
      "Epoch 357, Loss: 0.6758482456207275\n",
      "Validation Loss: 0.661992609500885\n",
      "Epoch 358, Loss: 0.661992609500885\n",
      "Validation Loss: 0.650244951248169\n",
      "Epoch 359, Loss: 0.650244951248169\n",
      "Validation Loss: 0.6517319679260254\n",
      "Epoch 360, Loss: 0.6517319679260254\n",
      "Validation Loss: 0.6266568303108215\n",
      "Epoch 361, Loss: 0.6266568303108215\n",
      "Validation Loss: 0.6514424681663513\n",
      "Epoch 362, Loss: 0.6514424681663513\n",
      "Validation Loss: 0.6155429482460022\n",
      "Epoch 363, Loss: 0.6155429482460022\n",
      "Validation Loss: 0.6476491689682007\n",
      "Epoch 364, Loss: 0.6476491689682007\n",
      "Validation Loss: 0.6431746482849121\n",
      "Epoch 365, Loss: 0.6431746482849121\n",
      "Validation Loss: 0.6686903834342957\n",
      "Epoch 366, Loss: 0.6686903834342957\n",
      "Validation Loss: 0.6576403975486755\n",
      "Epoch 367, Loss: 0.6576403975486755\n",
      "Validation Loss: 0.6522270441055298\n",
      "Epoch 368, Loss: 0.6522270441055298\n",
      "Validation Loss: 0.6367730498313904\n",
      "Epoch 369, Loss: 0.6367730498313904\n",
      "Validation Loss: 0.6334458589553833\n",
      "Epoch 370, Loss: 0.6334458589553833\n",
      "Validation Loss: 0.6534571051597595\n",
      "Epoch 371, Loss: 0.6534571051597595\n",
      "Validation Loss: 0.6162012219429016\n",
      "Epoch 372, Loss: 0.6162012219429016\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import RGCNConv\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=0.001)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(500):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    out = model(train_data.x_dict, train_data.edge_index_dict)\n",
    "    loss = criterion(out['recipe'], train_data['recipe'].y.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
    "    \n",
    "        # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "    \n",
    "        out = model(val_data.x_dict, val_data.edge_index_dict)\n",
    "        loss = criterion(out[\"recipe\"], val_data[\"recipe\"].y)\n",
    "        val_loss += loss.item()\n",
    "        print(f\"Validation Loss: {val_loss}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-10-19T12:11:42.278009600Z"
    }
   },
   "id": "f332b1ab2bdecc74"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.3247435092926025\n",
      "F1 Score: 0.16283586921333765\n",
      "Precision: 0.2678381256656017\n",
      "Recall: 0.1169767441860465\n",
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# For evaluation metrics, you can use sklearn's metrics\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "# Convert the model's output to binary labels\n",
    "def to_binary_labels(output):\n",
    "    return (torch.sigmoid(output) > 0.5).int()\n",
    "\n",
    "# Evaluate on validation set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  # Assuming val_data is your validation data\n",
    "    out = model(test_data.x_dict, test_data.edge_index_dict)\n",
    "    test_loss = criterion(out['recipe'], test_data['recipe'].y.float())\n",
    "    print(f\"Test Loss: {test_loss.item()}\")\n",
    "\n",
    "    # Convert outputs to binary labels for metric calculation\n",
    "    preds = to_binary_labels(out['recipe'])\n",
    "    labels = test_data['recipe'].y.int()\n",
    "\n",
    "    f1 = f1_score(labels.numpy(), preds.numpy(), average='micro')\n",
    "    precision = precision_score(labels.numpy(), preds.numpy(), average='micro')\n",
    "    recall = recall_score(labels.numpy(), preds.numpy(), average='micro')\n",
    "    accuracy = accuracy_score(labels.numpy(), preds.numpy())\n",
    "\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"Accuracy: {accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T12:10:30.167979100Z",
     "start_time": "2023-10-19T12:10:29.732413700Z"
    }
   },
   "id": "887039b8df14d594"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
